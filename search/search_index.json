{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Kafka Connect OpenTelemetry Source Connector","text":"<p>Receive OpenTelemetry Protocol (OTLP) telemetry data from any application and stream it directly into Apache Kafka with automatic signal type routing, dual protocol support, and comprehensive monitoring.</p> <p>Get Started View on GitHub</p>"},{"location":"#features","title":"Features","text":""},{"location":"#dual-protocol-support","title":"Dual Protocol Support","text":"<p>Accept OTLP data via both gRPC (port 4317) and HTTP (port 4318) protocols simultaneously, supporting all OpenTelemetry SDK clients.</p>"},{"location":"#three-signal-types","title":"Three Signal Types","text":"<p>Automatically route traces, metrics, and logs to separate Kafka topics for downstream processing and analysis.</p>"},{"location":"#flexible-output-formats","title":"Flexible Output Formats","text":"<p>Choose between JSON (human-readable) or Protobuf (base64-encoded binary) output formats to optimize for your use case.</p>"},{"location":"#jmx-metrics-monitoring","title":"JMX Metrics Monitoring","text":"<p>Built-in comprehensive metrics via JMX including message counts, queue utilization, drop rates, and per-signal statistics.</p>"},{"location":"#high-throughput","title":"High Throughput","text":"<p>Configurable message queues with backpressure handling and sequence-based offset management for reliable delivery.</p>"},{"location":"#production-ready","title":"Production Ready","text":"<p>Reliable offset-based delivery guarantees, graceful shutdown handling, and detailed operational runbooks.</p>"},{"location":"#quick-example","title":"Quick Example","text":"<p>Stream telemetry from your OpenTelemetry-instrumented applications into Kafka:</p> Connector ConfigurationDeploy ConnectorConfigure OTEL SDKConsume Traces <pre><code>{\n  \"name\": \"otlp-source-connector\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n    \"tasks.max\": \"1\",\n\n    \"otlp.grpc.enabled\": \"true\",\n    \"otlp.grpc.port\": \"4317\",\n    \"otlp.http.enabled\": \"true\",\n    \"otlp.http.port\": \"4318\",\n\n    \"kafka.topic.traces\": \"otlp-traces\",\n    \"kafka.topic.metrics\": \"otlp-metrics\",\n    \"kafka.topic.logs\": \"otlp-logs\",\n\n    \"otlp.message.format\": \"json\"\n  }\n}\n</code></pre> <pre><code>curl -X POST http://localhost:8083/connectors \\\n  -H \"Content-Type: application/json\" \\\n  -d @otlp-connector.json\n</code></pre> <pre><code># Point your application to the connector\nexport OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318\nexport OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf\nexport OTEL_SERVICE_NAME=my-application\n\n# Run your instrumented application\njava -javaagent:opentelemetry-javaagent.jar \\\n  -jar my-application.jar\n</code></pre> <pre><code>kafka-console-consumer.sh \\\n  --bootstrap-server localhost:9092 \\\n  --topic otlp-traces \\\n  --from-beginning \\\n  --property print.key=true\n</code></pre>"},{"location":"#use-cases","title":"Use Cases","text":"<p>The connector is ideal for building observability pipelines with Kafka:</p> <ul> <li>Observability Pipelines - Ingest telemetry from microservices into Kafka for processing, enrichment, and routing</li> <li>Log Aggregation - Collect application logs via OTLP and stream to Kafka for centralized analysis</li> <li>Trace Storage - Store distributed traces in Kafka for replay, analysis, and long-term retention</li> <li>Metrics Collection - Aggregate application metrics into Kafka for real-time monitoring and alerting</li> <li>Multi-Backend Routing - Fan out telemetry to multiple observability backends (Jaeger, Prometheus, Elasticsearch)</li> <li>Telemetry Buffering - Use Kafka as a buffer between applications and observability backends for reliability</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<pre><code>graph LR\n    A1[Java App] --&gt;|OTLP/gRPC:4317| E[OTLP Receiver]\n    A2[Python App] --&gt;|OTLP/HTTP:4318| E\n    A3[Go App] --&gt;|OTLP/gRPC:4317| E\n\n    E --&gt; F{Signal Router}\n\n    F --&gt;|Traces| T[otlp-traces]\n    F --&gt;|Metrics| M[otlp-metrics]\n    F --&gt;|Logs| L[otlp-logs]\n\n    T --&gt; B1[Jaeger]\n    M --&gt; B2[Prometheus]\n    L --&gt; B3[Elasticsearch]\n\n    T --&gt; B4[Data Lake]\n    M --&gt; B4\n    L --&gt; B4\n\n    style A1 fill:#3b82f6\n    style A2 fill:#3b82f6\n    style A3 fill:#3b82f6\n    style E fill:#f59e0b\n    style F fill:#f59e0b\n    style T fill:#10b981\n    style M fill:#10b981\n    style L fill:#10b981\n    style B1 fill:#ef4444\n    style B2 fill:#ef4444\n    style B3 fill:#ef4444\n    style B4 fill:#ef4444</code></pre> <p>The connector acts as an OTLP receiver endpoint that applications send telemetry to. It automatically routes traces, metrics, and logs to separate Kafka topics, where downstream consumers can process and forward them to various observability backends.</p>"},{"location":"#why-this-connector","title":"Why This Connector?","text":"Feature Kafka Connect OTLP OpenTelemetry Collector Direct to Backend Kafka-native \u2705 Built-in \u26a0\ufe0f Requires Kafka exporter \u274c No Kafka support Signal routing \u2705 Automatic \u26a0\ufe0f Manual config \u274c Single backend Deployment \u2705 Kafka Connect \u26a0\ufe0f Separate service \u2705 Simple Monitoring \u2705 JMX/Prometheus \u2705 Built-in \u26a0\ufe0f Backend-specific Buffering \u2705 Kafka topics \u26a0\ufe0f Memory only \u274c No buffer Multi-backend \u2705 Fan-out pattern \u2705 Processors \u274c Single target Maintenance \u2705 Integrated \u26a0\ufe0f DIY \u2705 Vendor-managed"},{"location":"#performance","title":"Performance","text":"<ul> <li>Throughput: Handles 10,000+ spans/metrics/logs per second on standard hardware</li> <li>Latency: &lt; 10ms from OTLP receipt to Kafka produce</li> <li>Reliability: Sequence-based offset management prevents message loss</li> <li>Scalability: Configurable queue size for traffic bursts</li> </ul>"},{"location":"#comparison-with-opentelemetry-collector","title":"Comparison with OpenTelemetry Collector","text":""},{"location":"#when-to-use-this-connector","title":"When to use this connector:","text":"<ul> <li>You're already using Kafka as your data backbone</li> <li>You want to leverage Kafka's durability and replay capabilities</li> <li>You need to fan out telemetry to multiple consumers</li> <li>You want centralized observability data in Kafka topics</li> <li>You're building custom telemetry processing pipelines</li> </ul>"},{"location":"#when-to-use-otel-collector","title":"When to use OTEL Collector:","text":"<ul> <li>You need advanced telemetry transformations</li> <li>You require direct exports to 50+ observability backends</li> <li>You don't need Kafka in your architecture</li> <li>You need sophisticated sampling and filtering</li> </ul>"},{"location":"#use-both-together","title":"Use both together:","text":"<p>Many production deployments use both:</p> <ol> <li>Applications \u2192 OTLP Connector \u2192 Kafka topics</li> <li>Kafka topics \u2192 OTEL Collector \u2192 Various backends</li> </ol> <p>This provides Kafka's durability + Collector's flexibility.</p>"},{"location":"#opentelemetry-sdk-configuration-examples","title":"OpenTelemetry SDK Configuration Examples","text":""},{"location":"#java-application","title":"Java Application","text":"<pre><code>import io.opentelemetry.api.OpenTelemetry;\nimport io.opentelemetry.exporter.otlp.trace.OtlpGrpcSpanExporter;\nimport io.opentelemetry.sdk.OpenTelemetrySdk;\nimport io.opentelemetry.sdk.trace.SdkTracerProvider;\nimport io.opentelemetry.sdk.trace.export.BatchSpanProcessor;\n\n// Configure OTLP exporter to send to connector\nOtlpGrpcSpanExporter spanExporter = OtlpGrpcSpanExporter.builder()\n    .setEndpoint(\"http://kafka-connect-host:4317\")\n    .build();\n\nSdkTracerProvider tracerProvider = SdkTracerProvider.builder()\n    .addSpanProcessor(BatchSpanProcessor.builder(spanExporter).build())\n    .build();\n\nOpenTelemetry openTelemetry = OpenTelemetrySdk.builder()\n    .setTracerProvider(tracerProvider)\n    .buildAndRegisterGlobal();\n</code></pre>"},{"location":"#python-application","title":"Python Application","text":"<pre><code>from opentelemetry import trace\nfrom opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\n# Configure OTLP exporter\ntrace.set_tracer_provider(TracerProvider())\ntracer_provider = trace.get_tracer_provider()\n\notlp_exporter = OTLPSpanExporter(\n    endpoint=\"http://kafka-connect-host:4317\",\n    insecure=True\n)\n\ntracer_provider.add_span_processor(BatchSpanProcessor(otlp_exporter))\n</code></pre>"},{"location":"#go-application","title":"Go Application","text":"<pre><code>package main\n\nimport (\n    \"go.opentelemetry.io/otel\"\n    \"go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc\"\n    sdktrace \"go.opentelemetry.io/otel/sdk/trace\"\n)\n\nfunc main() {\n    // Configure OTLP exporter\n    exporter, _ := otlptracegrpc.New(\n        context.Background(),\n        otlptracegrpc.WithEndpoint(\"kafka-connect-host:4317\"),\n        otlptracegrpc.WithInsecure(),\n    )\n\n    tp := sdktrace.NewTracerProvider(\n        sdktrace.WithBatcher(exporter),\n    )\n\n    otel.SetTracerProvider(tp)\n}\n</code></pre>"},{"location":"#environment-variables-all-languages","title":"Environment Variables (All Languages)","text":"<pre><code># gRPC endpoint\nexport OTEL_EXPORTER_OTLP_ENDPOINT=http://kafka-connect-host:4317\nexport OTEL_EXPORTER_OTLP_PROTOCOL=grpc\n\n# HTTP endpoint\nexport OTEL_EXPORTER_OTLP_ENDPOINT=http://kafka-connect-host:4318\nexport OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf\n\n# Service identification\nexport OTEL_SERVICE_NAME=my-application\nexport OTEL_RESOURCE_ATTRIBUTES=environment=production,version=1.0.0\n</code></pre>"},{"location":"#operational-features","title":"Operational Features","text":"<p>Includes comprehensive operational tooling:</p> <ul> <li>JMX Metrics: Per-signal counters (received/dropped/produced), queue statistics, drop rates</li> <li>Structured Logging: Event-based logs for easy parsing and alerting</li> <li>Graceful Shutdown: Clean shutdown with in-flight message completion</li> <li>Operational Runbook: Detailed troubleshooting and recovery procedures</li> <li>Health Checks: JMX-based health monitoring examples</li> </ul>"},{"location":"#message-format-examples","title":"Message Format Examples","text":""},{"location":"#json-format-default","title":"JSON Format (Default)","text":"<p>Human-readable format for debugging and downstream JSON processing:</p> <pre><code>{\n  \"resourceSpans\": [\n    {\n      \"resource\": {\n        \"attributes\": [\n          {\n            \"key\": \"service.name\",\n            \"value\": { \"stringValue\": \"checkout-service\" }\n          },\n          {\n            \"key\": \"service.version\",\n            \"value\": { \"stringValue\": \"1.0.0\" }\n          }\n        ]\n      },\n      \"scopeSpans\": [\n        {\n          \"scope\": {\n            \"name\": \"checkout-tracer\"\n          },\n          \"spans\": [\n            {\n              \"traceId\": \"5B8EFFF798038103D269B633813FC60C\",\n              \"spanId\": \"EEE19B7EC3C1B174\",\n              \"name\": \"process-payment\",\n              \"kind\": \"SPAN_KIND_INTERNAL\",\n              \"startTimeUnixNano\": \"1609459200000000000\",\n              \"endTimeUnixNano\": \"1609459200500000000\",\n              \"attributes\": [\n                {\n                  \"key\": \"payment.amount\",\n                  \"value\": { \"doubleValue\": 99.99 }\n                }\n              ]\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"#protobuf-format","title":"Protobuf Format","text":"<p>Compact binary format (base64-encoded) for high-volume production:</p> <pre><code>CiYKFgoKc2VydmljZS5uYW1lEggSBmNoZWNrb3V0LXNlcnZpY2UKHgoTc2VydmljZS52ZXJzaW9u...\n</code></pre> <p>Decode downstream using OTLP protobuf definitions.</p>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li>GitHub Issues: Report bugs and request features</li> <li>Slack Community: Join Conduktor Slack</li> <li>Documentation: Full reference guide</li> </ul>"},{"location":"#license","title":"License","text":"<p>Apache License 2.0 - see LICENSE for details.</p>"},{"location":"#ready-to-get-started","title":"Ready to Get Started?","text":"<p>Getting Started Guide View on GitHub See FAQ</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to the Kafka Connect OpenTelemetry Source Connector will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#planned-features","title":"Planned Features","text":"<ul> <li> TLS support for OTLP receivers (gRPC and HTTP)</li> <li> Custom authentication mechanisms (API keys, mTLS)</li> <li> Configurable message transformations (SMTs)</li> <li> Metrics dashboard templates (Grafana)</li> <li> Helm chart for Kubernetes deployments</li> <li> Resource attribute filtering</li> <li> Sampling configuration (head-based, tail-based)</li> </ul>"},{"location":"changelog/#100-2025-12-17","title":"1.0.0 - 2025-12-17","text":""},{"location":"changelog/#added","title":"Added","text":""},{"location":"changelog/#core-features","title":"Core Features","text":"<ul> <li>Initial release of Kafka Connect OpenTelemetry Source Connector</li> <li>OTLP receiver for traces, metrics, and logs</li> <li>Dual protocol support: gRPC (port 4317) and HTTP (port 4318)</li> <li>Automatic signal type routing to separate Kafka topics</li> <li>Flexible output formats: JSON and Protobuf (base64-encoded)</li> <li>Configurable message queues with backpressure handling (per signal type)</li> <li>Sequence-based offset management for reliable delivery</li> <li>Graceful shutdown with in-flight message completion</li> </ul>"},{"location":"changelog/#otlp-protocol-support","title":"OTLP Protocol Support","text":"<ul> <li>gRPC receiver on port 4317 (configurable)</li> <li><code>opentelemetry.proto.collector.trace.v1.TraceService</code></li> <li><code>opentelemetry.proto.collector.metrics.v1.MetricsService</code></li> <li><code>opentelemetry.proto.collector.logs.v1.LogsService</code></li> <li>HTTP receiver on port 4318 (configurable)</li> <li><code>/v1/traces</code> endpoint</li> <li><code>/v1/metrics</code> endpoint</li> <li><code>/v1/logs</code> endpoint</li> <li>Support for all OpenTelemetry SDKs (Java, Python, Go, Node.js, .NET, Ruby, etc.)</li> <li>Automatic gzip compression support (gRPC and HTTP)</li> </ul>"},{"location":"changelog/#configuration","title":"Configuration","text":"<ul> <li>Required parameters:</li> <li><code>connector.class</code> - Connector class name</li> <li><code>tasks.max</code> - Number of tasks (must be 1)</li> <li>OTLP receiver configuration:</li> <li><code>otlp.grpc.enabled</code> - Enable/disable gRPC receiver (default: true)</li> <li><code>otlp.grpc.port</code> - gRPC port (default: 4317)</li> <li><code>otlp.http.enabled</code> - Enable/disable HTTP receiver (default: true)</li> <li><code>otlp.http.port</code> - HTTP port (default: 4318)</li> <li><code>otlp.bind.address</code> - Bind address (default: 0.0.0.0)</li> <li>Kafka topic configuration:</li> <li><code>kafka.topic.traces</code> - Traces topic (default: otlp-traces)</li> <li><code>kafka.topic.metrics</code> - Metrics topic (default: otlp-metrics)</li> <li><code>kafka.topic.logs</code> - Logs topic (default: otlp-logs)</li> <li>Message format configuration:</li> <li><code>otlp.message.format</code> - Output format: json or protobuf (default: json)</li> <li><code>otlp.message.queue.size</code> - Queue size per signal (default: 10000)</li> </ul>"},{"location":"changelog/#monitoring-observability","title":"Monitoring &amp; Observability","text":"<ul> <li>JMX metrics exposure via Kafka Connect framework</li> <li>Built-in metrics:</li> <li>Counters: TracesReceived, MetricsReceived, LogsReceived, TracesDropped, MetricsDropped, LogsDropped, RecordsProduced</li> <li>Queue Metrics: TracesQueueSize, MetricsQueueSize, LogsQueueSize, QueueCapacity, MaxQueueUtilizationPercent</li> <li>Derived Metrics: TotalMessagesReceived, TotalMessagesDropped, TotalLagCount, DropRate</li> <li>Structured logging with <code>event=</code> prefix:</li> <li><code>event=task_starting</code> - Task initialization</li> <li><code>event=otlp_receiver_started</code> - OTLP receivers started</li> <li><code>event=trace_received</code>, <code>event=metric_received</code>, <code>event=log_received</code> - Signal reception</li> <li><code>event=trace_dropped</code>, <code>event=metric_dropped</code>, <code>event=log_dropped</code> - Queue overflow</li> <li><code>event=task_metrics</code> - Periodic metrics log (every 30 seconds)</li> <li><code>event=task_stopping</code> - Graceful shutdown</li> <li>Integration with Prometheus via JMX Exporter</li> <li>Sample Grafana dashboard configuration</li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>Comprehensive README with installation, configuration, and usage examples</li> <li>Quick start guide with OpenTelemetry SDK examples (Java, Python, Go)</li> <li>Detailed configuration reference with all parameters</li> <li>Troubleshooting guide with common issues and solutions</li> <li>OpenTelemetry SDK integration examples for multiple languages</li> <li>Architecture documentation with data flow diagrams</li> <li>Production deployment recommendations</li> <li>Operational runbook for monitoring and troubleshooting</li> <li>FAQ covering common questions and use cases</li> </ul>"},{"location":"changelog/#testing","title":"Testing","text":"<ul> <li>Unit tests for connector, configuration, and offset management</li> <li>Integration tests with gRPC and HTTP receivers</li> <li>Configuration validation tests</li> <li>Offset commit and recovery tests</li> <li>Queue overflow and backpressure tests</li> </ul>"},{"location":"changelog/#dependencies","title":"Dependencies","text":"<ul> <li>Apache Kafka Connect API 3.9.0</li> <li>gRPC 1.59.0</li> <li>Protobuf 3.25.0</li> <li>OpenTelemetry Protocol definitions 1.0.0</li> <li>SLF4J logging API 1.7.36</li> <li>JUnit 5.9.2 (testing)</li> <li>Mockito 5.2.0 (testing)</li> </ul>"},{"location":"changelog/#technical-details","title":"Technical Details","text":""},{"location":"changelog/#architecture","title":"Architecture","text":"<ul> <li>OpenTelemetrySourceConnector: Main connector class managing configuration and task lifecycle</li> <li>OpenTelemetrySourceTask: Task implementation running OTLP receivers and message polling</li> <li>OtlpGrpcReceiver: gRPC server implementing OTLP trace/metrics/logs services</li> <li>OtlpHttpReceiver: HTTP server handling /v1/traces, /v1/metrics, /v1/logs endpoints</li> <li>SignalRouter: Routes incoming signals to appropriate queues (traces/metrics/logs)</li> <li>OffsetManager: Manages sequence-based offsets for each signal type</li> <li>OpenTelemetrySourceConnectorConfig: Configuration definition with validation</li> </ul>"},{"location":"changelog/#data-flow","title":"Data Flow","text":"<pre><code>OpenTelemetry Apps\n    |\n    | OTLP/gRPC (4317)\n    | OTLP/HTTP (4318)\n    v\nOTLP Receivers (gRPC + HTTP)\n    |\n    v\nSignal Router\n    |\n    +---+---+---+\n    |   |   |   |\n    v   v   v   v\nTraces Metrics Logs Queues\n    |   |   |   |\n    v   v   v   v\nSourceTask.poll()\n    |\n    v\nKafka Topics (otlp-traces, otlp-metrics, otlp-logs)\n</code></pre>"},{"location":"changelog/#message-format","title":"Message Format","text":"<p>JSON Format (Default): - Human-readable JSON using protobuf JSON mapping - Larger size (~3-5x protobuf) - Easier debugging and downstream processing</p> <p>Protobuf Format: - Base64-encoded binary protobuf - Smaller size, faster serialization - Requires protobuf decoder downstream</p>"},{"location":"changelog/#delivery-semantics","title":"Delivery Semantics","text":"<ul> <li>At-least-once delivery with offset management</li> <li>Sequence numbers for each signal type</li> <li>Offsets committed to Kafka Connect offset storage</li> <li>Messages may be duplicated on failure/restart</li> <li>Messages can be dropped on queue overflow (monitor JMX metrics)</li> </ul>"},{"location":"changelog/#known-limitations","title":"Known Limitations","text":"<ul> <li>Single task per connector (OTLP receiver runs on specific ports)</li> <li>No built-in TLS support (planned for future release)</li> <li>No custom authentication (planned for future release)</li> <li>Queue overflow drops messages (monitor queue utilization)</li> <li>gRPC and HTTP ports must be available</li> </ul>"},{"location":"changelog/#known-issues","title":"Known Issues","text":"<ul> <li>None reported in initial release</li> </ul>"},{"location":"changelog/#breaking-changes","title":"Breaking Changes","text":"<p>N/A - Initial release</p>"},{"location":"changelog/#version-history-format","title":"Version History Format","text":""},{"location":"changelog/#xyz-yyyy-mm-dd","title":"[X.Y.Z] - YYYY-MM-DD","text":""},{"location":"changelog/#added_1","title":"Added","text":"<p>Features or capabilities that were added in this release.</p>"},{"location":"changelog/#changed","title":"Changed","text":"<p>Changes in existing functionality or behavior.</p>"},{"location":"changelog/#deprecated","title":"Deprecated","text":"<p>Features that will be removed in future releases.</p>"},{"location":"changelog/#removed","title":"Removed","text":"<p>Features that were removed in this release.</p>"},{"location":"changelog/#fixed","title":"Fixed","text":"<p>Bug fixes and error corrections.</p>"},{"location":"changelog/#security","title":"Security","text":"<p>Security vulnerability fixes and improvements.</p>"},{"location":"changelog/#upgrade-guide","title":"Upgrade Guide","text":""},{"location":"changelog/#from-pre-release-to-100","title":"From Pre-Release to 1.0.0","text":"<p>This is the initial stable release. No migration required.</p>"},{"location":"changelog/#future-upgrades","title":"Future Upgrades","text":"<p>Upgrade instructions will be provided here for future releases.</p>"},{"location":"changelog/#support-policy","title":"Support Policy","text":""},{"location":"changelog/#version-support","title":"Version Support","text":"<ul> <li>Latest stable version: Full support with bug fixes and security updates</li> <li>Previous minor version: Security fixes only</li> <li>Older versions: Community support via GitHub Issues</li> </ul>"},{"location":"changelog/#compatibility-matrix","title":"Compatibility Matrix","text":"Connector Version Min Kafka Version Max Kafka Version Java Version OTLP Version 1.0.0 3.9.0 Latest 11+ 1.0.0"},{"location":"changelog/#release-notes-archive","title":"Release Notes Archive","text":""},{"location":"changelog/#release-highlights","title":"Release Highlights","text":""},{"location":"changelog/#100-initial-stable-release-2025-12-17","title":"1.0.0 - Initial Stable Release (2025-12-17)","text":"<p>\ud83c\udf89 First Production-Ready Release</p> <p>The Kafka Connect OpenTelemetry Source Connector is now production-ready with comprehensive features for receiving OTLP telemetry and streaming it into Apache Kafka.</p> <p>Key Capabilities: - Receive traces, metrics, and logs from any OpenTelemetry-instrumented application - Support for both gRPC (4317) and HTTP (4318) OTLP protocols - Automatic routing to separate Kafka topics per signal type - Flexible JSON or Protobuf output formats - Configurable queues with backpressure handling</p> <p>Production Features: - Sequence-based offset management for reliable delivery - Built-in JMX metrics for monitoring - Comprehensive error handling and logging - Prometheus/Grafana integration support - Graceful shutdown with in-flight message completion</p> <p>Use Cases: - Build observability pipelines with Kafka - Buffer telemetry before sending to backends - Fan-out telemetry to multiple consumers - Long-term trace/metrics/logs storage - Decouple apps from specific observability backends</p> <p>Getting Started: <pre><code>mvn clean package\ncp target/kafka-connect-opentelemetry-1.0.0-jar-with-dependencies.jar \\\n   $KAFKA_HOME/plugins/kafka-connect-opentelemetry/\n</code></pre></p> <p>Example Configuration: <pre><code>{\n  \"name\": \"otlp-source\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n    \"tasks.max\": \"1\",\n    \"otlp.grpc.port\": \"4317\",\n    \"otlp.http.port\": \"4318\",\n    \"kafka.topic.traces\": \"otlp-traces\",\n    \"kafka.topic.metrics\": \"otlp-metrics\",\n    \"kafka.topic.logs\": \"otlp-logs\",\n    \"otlp.message.format\": \"json\"\n  }\n}\n</code></pre></p> <p>Important Notes: - At-least-once delivery semantics (sequence-based offsets) - Single task per connector (port binding limitation) - Monitor queue utilization to prevent message drops - TLS support planned for future release</p>"},{"location":"changelog/#contributing-to-changelog","title":"Contributing to Changelog","text":"<p>When submitting a PR, please update the <code>[Unreleased]</code> section with your changes under the appropriate category (Added, Changed, Fixed, etc.).</p> <p>Format: <pre><code>### Category\n- Brief description of change ([#PR_NUMBER](link))\n</code></pre></p> <p>Example: <pre><code>### Added\n- TLS support for OTLP receivers ([#42](https://github.com/conduktor/kafka-connect-opentelemetry/pull/42))\n\n### Fixed\n- Memory leak in queue overflow scenario ([#38](https://github.com/conduktor/kafka-connect-opentelemetry/pull/38))\n</code></pre></p>"},{"location":"changelog/#links","title":"Links","text":"<ul> <li>GitHub Repository</li> <li>Issue Tracker</li> <li>Documentation</li> <li>Conduktor Website</li> </ul>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>Common questions and answers about the Kafka Connect OpenTelemetry connector.</p>"},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#what-is-this-connector-used-for","title":"What is this connector used for?","text":"<p>The Kafka Connect OpenTelemetry connector receives telemetry data (traces, metrics, logs) from OpenTelemetry-instrumented applications via OTLP protocol and streams it into Kafka topics. It's ideal for:</p> <ul> <li>Building observability pipelines with Kafka as the central data platform</li> <li>Buffering telemetry data before sending to observability backends</li> <li>Long-term storage and replay of traces, metrics, and logs</li> <li>Fan-out telemetry to multiple downstream consumers</li> <li>Decoupling applications from specific observability backends</li> <li>Aggregating telemetry from microservices architectures</li> </ul>"},{"location":"faq/#how-does-it-differ-from-the-opentelemetry-collector","title":"How does it differ from the OpenTelemetry Collector?","text":"Feature Kafka Connect OTLP OpenTelemetry Collector Primary Purpose Kafka ingestion Multi-backend export Kafka Support Native, built-in Via Kafka exporter Signal Routing Automatic to topics Manual configuration Deployment Kafka Connect framework Standalone service Buffering Kafka topics (durable) Memory (volatile) Transformations Kafka Streams/ksqlDB Built-in processors Best For Kafka-centric pipelines Direct backend export <p>Use both together: Many deployments use this connector to ingest into Kafka, then use OTEL Collector to consume from Kafka and export to multiple backends.</p>"},{"location":"faq/#what-delivery-guarantees-does-this-connector-provide","title":"What delivery guarantees does this connector provide?","text":"<p>The connector provides at-least-once delivery semantics with sequence-based offset management:</p> <ul> <li>Messages are tracked with sequence numbers</li> <li>Offsets are committed to Kafka Connect offset storage</li> <li>On restart, the connector resumes from the last committed offset</li> <li>Messages may be duplicated during failures (at-least-once)</li> <li>Messages are never lost if Kafka is properly configured</li> </ul> <p>Queue Overflow Scenarios</p> <p>Messages can be dropped if all three signal queues fill up (when <code>TracesDropped</code>, <code>MetricsDropped</code>, or <code>LogsDropped</code> &gt; 0). Monitor queue utilization and increase <code>otlp.message.queue.size</code> if needed.</p>"},{"location":"faq/#installation-setup","title":"Installation &amp; Setup","text":""},{"location":"faq/#do-i-need-to-build-from-source","title":"Do I need to build from source?","text":"<p>For now, yes. Pre-built JARs will be available from GitHub Releases in future versions:</p> <pre><code># Build from source\nmvn clean package\n\n# Copy JAR to plugin directory\ncp target/kafka-connect-opentelemetry-1.0.0-jar-with-dependencies.jar \\\n   $KAFKA_HOME/plugins/kafka-connect-opentelemetry/\n</code></pre>"},{"location":"faq/#which-kafka-version-do-i-need","title":"Which Kafka version do I need?","text":"<p>Minimum: Kafka 3.9.0 Recommended: Latest stable Kafka version</p> <p>The connector uses Kafka Connect API features available in 3.9.0+.</p>"},{"location":"faq/#can-i-use-this-with-confluent-platform","title":"Can I use this with Confluent Platform?","text":"<p>Yes, the connector works with:</p> <ul> <li>Apache Kafka (open source)</li> <li>Confluent Platform</li> <li>Amazon MSK (Managed Streaming for Kafka)</li> <li>Azure Event Hubs for Kafka</li> <li>Any Kafka-compatible platform supporting Connect API</li> </ul>"},{"location":"faq/#where-should-i-install-the-connector-jar","title":"Where should I install the connector JAR?","text":"<p>Install in the Kafka Connect plugin directory:</p> <pre><code># Default locations\n/usr/local/share/kafka/plugins/kafka-connect-opentelemetry/\n# or\n$KAFKA_HOME/plugins/kafka-connect-opentelemetry/\n</code></pre> <p>Ensure <code>plugin.path</code> in <code>connect-distributed.properties</code> includes this location.</p>"},{"location":"faq/#do-i-need-separate-dependency-jars","title":"Do I need separate dependency JARs?","text":"<p>No. The release JAR (<code>kafka-connect-opentelemetry-X.X.X-jar-with-dependencies.jar</code>) includes all dependencies (gRPC, Protobuf, etc.). Just download and deploy the single JAR file.</p>"},{"location":"faq/#configuration","title":"Configuration","text":""},{"location":"faq/#whats-the-minimum-configuration","title":"What's the minimum configuration?","text":"<p>Only the connector class is required:</p> <pre><code>{\n  \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n  \"tasks.max\": \"1\"\n}\n</code></pre> <p>This uses defaults: gRPC on 4317, HTTP on 4318, topics <code>otlp-traces/metrics/logs</code>, JSON format.</p>"},{"location":"faq/#how-do-i-receive-only-traces-or-only-metricslogs","title":"How do I receive only traces (or only metrics/logs)?","text":"<p>You can't disable specific signal types - the connector receives all three. However, you can:</p> <ol> <li> <p>Route to the same topic (if you don't need separation):    <pre><code>{\n  \"kafka.topic.traces\": \"all-telemetry\",\n  \"kafka.topic.metrics\": \"all-telemetry\",\n  \"kafka.topic.logs\": \"all-telemetry\"\n}\n</code></pre></p> </li> <li> <p>Filter downstream using Kafka Streams or consumers</p> </li> <li> <p>Configure SDK to send only specific signals (recommended approach)</p> </li> </ol>"},{"location":"faq/#should-i-use-json-or-protobuf-format","title":"Should I use JSON or Protobuf format?","text":"Scenario Recommended Format Reason Development/Testing JSON Human-readable, easy debugging Low-volume production JSON Simpler downstream processing High-volume production Protobuf 3-5x smaller, faster serialization Downstream JSON processors JSON No decoding needed Downstream analytics (Spark, Flink) Protobuf More efficient processing <p>Tip: Start with JSON, switch to Protobuf when scaling.</p>"},{"location":"faq/#can-i-use-custom-topic-names","title":"Can I use custom topic names?","text":"<p>Yes! Use environment or application-specific names:</p> <pre><code>{\n  \"kafka.topic.traces\": \"prod-checkout-traces\",\n  \"kafka.topic.metrics\": \"prod-checkout-metrics\",\n  \"kafka.topic.logs\": \"prod-checkout-logs\"\n}\n</code></pre>"},{"location":"faq/#how-many-tasks-should-i-configure","title":"How many tasks should I configure?","text":"<p>Always 1 task (<code>tasks.max: \"1\"</code>).</p> <p>The connector runs a single OTLP receiver server instance per connector. Each connector binds to specific ports (4317, 4318), so you cannot run multiple tasks.</p> <p>To scale: Deploy multiple connector instances on different ports, not multiple tasks.</p>"},{"location":"faq/#opentelemetry-sdk-integration","title":"OpenTelemetry SDK Integration","text":""},{"location":"faq/#which-opentelemetry-sdks-are-supported","title":"Which OpenTelemetry SDKs are supported?","text":"<p>All official OpenTelemetry SDKs that support OTLP export:</p> <ul> <li>Java (opentelemetry-java)</li> <li>Python (opentelemetry-python)</li> <li>Go (opentelemetry-go)</li> <li>Node.js (opentelemetry-js)</li> <li>.NET (opentelemetry-dotnet)</li> <li>Ruby (opentelemetry-ruby)</li> <li>PHP (opentelemetry-php)</li> <li>Rust (opentelemetry-rust)</li> </ul> <p>The connector implements standard OTLP gRPC and HTTP protocols.</p>"},{"location":"faq/#how-do-i-configure-my-application-to-send-to-the-connector","title":"How do I configure my application to send to the connector?","text":"<p>Environment variables (easiest):</p> <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=http://kafka-connect-host:4318\nexport OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf\nexport OTEL_SERVICE_NAME=my-application\n</code></pre> <p>Programmatic configuration:</p> <p>See examples in the main documentation.</p>"},{"location":"faq/#can-i-send-traces-and-metrics-to-different-endpoints","title":"Can I send traces and metrics to different endpoints?","text":"<p>Yes, use signal-specific environment variables:</p> <pre><code># Traces to connector\nexport OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=http://kafka-connect:4318/v1/traces\n\n# Metrics to different endpoint (e.g., Prometheus)\nexport OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=http://prometheus:4318/v1/metrics\n\n# Logs to connector\nexport OTEL_EXPORTER_OTLP_LOGS_ENDPOINT=http://kafka-connect:4318/v1/logs\n</code></pre>"},{"location":"faq/#does-the-connector-support-otlp-compression","title":"Does the connector support OTLP compression?","text":"<p>Yes, both gRPC and HTTP support compression:</p> <ul> <li>gRPC: Automatic gzip compression support</li> <li>HTTP: Supports <code>Content-Encoding: gzip</code> header</li> </ul> <p>Configure compression in your SDK:</p> <pre><code>export OTEL_EXPORTER_OTLP_COMPRESSION=gzip\n</code></pre>"},{"location":"faq/#data-reliability","title":"Data &amp; Reliability","text":""},{"location":"faq/#what-happens-to-messages-during-connector-restart","title":"What happens to messages during connector restart?","text":"<p>Graceful shutdown: - In-flight messages in queues are produced to Kafka before shutdown - Offset is committed after successful production - On restart, connector resumes from last committed offset - No message loss during graceful shutdown</p> <p>Ungraceful shutdown (crash): - Messages in queues may be lost - Last committed offset is used on restart - Messages received after last commit but before crash may be re-delivered (at-least-once)</p>"},{"location":"faq/#can-i-replay-historical-telemetry-data","title":"Can I replay historical telemetry data?","text":"<p>From Kafka: Yes (if using Kafka topics as long-term storage)</p> <pre><code># Consume from beginning\nkafka-console-consumer.sh \\\n  --bootstrap-server localhost:9092 \\\n  --topic otlp-traces \\\n  --from-beginning\n</code></pre> <p>From OTLP: No (OTLP is a streaming protocol with no built-in replay)</p>"},{"location":"faq/#what-data-format-does-the-connector-produce","title":"What data format does the connector produce?","text":"<p>Messages are produced as strings:</p> <ul> <li>JSON format: UTF-8 encoded JSON string</li> <li>Protobuf format: Base64-encoded binary string</li> </ul> <p>Message structure: <pre><code>{\n  \"topic\": \"otlp-traces\",\n  \"partition\": 2,\n  \"offset\": 12345,\n  \"key\": null,\n  \"value\": \"{\\\"resourceSpans\\\":[...]}\"  // JSON\n  // or\n  \"value\": \"CiYKFgoKc2VydmljZS5uYW1l...\"  // Protobuf (base64)\n}\n</code></pre></p>"},{"location":"faq/#how-do-i-process-protobuf-formatted-messages-downstream","title":"How do I process Protobuf-formatted messages downstream?","text":"<p>Kafka Streams example:</p> <pre><code>import io.opentelemetry.proto.trace.v1.TracesData;\nimport java.util.Base64;\n\n// Decode base64 + parse protobuf\nbyte[] decoded = Base64.getDecoder().decode(value);\nTracesData traces = TracesData.parseFrom(decoded);\n</code></pre> <p>Python example:</p> <pre><code>import base64\nfrom opentelemetry.proto.trace.v1.trace_pb2 import TracesData\n\n# Decode base64 + parse protobuf\ndecoded = base64.b64decode(value)\ntraces = TracesData.FromString(decoded)\n</code></pre>"},{"location":"faq/#operations","title":"Operations","text":""},{"location":"faq/#how-do-i-monitor-the-connector","title":"How do I monitor the connector?","text":"<p>Three approaches:</p> <ol> <li> <p>JMX Metrics (recommended):    <pre><code>jconsole &lt;kafka-connect-pid&gt;\n# Navigate to: io.conduktor.connect.otel \u2192 OpenTelemetryConnector\n</code></pre></p> </li> <li> <p>Connector Logs:    <pre><code>tail -f $KAFKA_HOME/logs/connect.log | grep \"event=\"\n</code></pre></p> </li> <li> <p>Kafka Connect REST API:    <pre><code>curl http://localhost:8083/connectors/otlp-source/status\n</code></pre></p> </li> </ol>"},{"location":"faq/#what-metrics-should-i-alert-on","title":"What metrics should I alert on?","text":"<p>Critical alerts:</p> <ul> <li>TracesDropped/MetricsDropped/LogsDropped &gt; 0 - Queue overflow, increase queue size</li> <li>Connector state != RUNNING - Connector failure, check logs</li> <li>DropRate &gt; 1% - Significant message loss</li> </ul> <p>Warning alerts:</p> <ul> <li>MaxQueueUtilizationPercent &gt; 80% - Approaching queue capacity</li> <li>TotalLagCount &gt; 10000 - Processing backlog</li> </ul> <p>See Operational Runbook for detailed monitoring setup.</p>"},{"location":"faq/#how-do-i-troubleshoot-high-queue-utilization","title":"How do I troubleshoot high queue utilization?","text":"<p>Check JMX metrics: <pre><code># TracesQueueSize, MetricsQueueSize, LogsQueueSize\n# MaxQueueUtilizationPercent\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Increase queue size:    <pre><code>\"otlp.message.queue.size\": \"50000\"\n</code></pre></p> </li> <li> <p>Optimize Kafka producer (in <code>connect-distributed.properties</code>):    <pre><code>producer.linger.ms=10\nproducer.batch.size=32768\nproducer.compression.type=lz4\n</code></pre></p> </li> <li> <p>Scale Kafka brokers (increase throughput)</p> </li> <li> <p>Switch to Protobuf (smaller messages, faster serialization)</p> </li> </ol>"},{"location":"faq/#how-do-i-update-connector-configuration","title":"How do I update connector configuration?","text":"<p>For running connectors:</p> <pre><code>curl -X PUT http://localhost:8083/connectors/otlp-source/config \\\n  -H \"Content-Type: application/json\" \\\n  -d @updated-config.json\n</code></pre> <p>The connector will restart automatically with the new configuration.</p> <p>Configuration changes requiring restart: - Port changes (<code>otlp.grpc.port</code>, <code>otlp.http.port</code>) - Protocol enable/disable (<code>otlp.grpc.enabled</code>, <code>otlp.http.enabled</code>) - Bind address (<code>otlp.bind.address</code>)</p>"},{"location":"faq/#can-i-pause-and-resume-the-connector","title":"Can I pause and resume the connector?","text":"<p>Yes, but with caveats:</p> <p>Pause: <pre><code>curl -X PUT http://localhost:8083/connectors/otlp-source/pause\n</code></pre></p> <p>Resume: <pre><code>curl -X PUT http://localhost:8083/connectors/otlp-source/resume\n</code></pre></p> <p>Telemetry Loss During Pause</p> <p>Pausing stops OTLP receivers - applications will fail to send telemetry during pause. Configure SDKs with retry logic or buffer telemetry.</p>"},{"location":"faq/#performance","title":"Performance","text":""},{"location":"faq/#what-throughput-can-i-expect","title":"What throughput can I expect?","text":"<p>Typical performance on standard hardware (4 CPU, 8 GB RAM):</p> <ul> <li>Traces: 5,000-10,000 spans/second</li> <li>Metrics: 10,000-20,000 data points/second</li> <li>Logs: 10,000-20,000 log records/second</li> </ul> <p>Actual throughput depends on: - Message size - Queue configuration - Kafka broker performance - Output format (Protobuf is faster)</p>"},{"location":"faq/#how-many-connectors-can-i-run","title":"How many connectors can I run?","text":"<p>One connector per port pair (gRPC + HTTP).</p> <p>Examples:</p> <pre><code>// Connector 1: Default ports\n{\"otlp.grpc.port\": \"4317\", \"otlp.http.port\": \"4318\"}\n\n// Connector 2: Custom ports\n{\"otlp.grpc.port\": \"5317\", \"otlp.http.port\": \"5318\"}\n\n// Connector 3: Different environment\n{\"otlp.grpc.port\": \"6317\", \"otlp.http.port\": \"6318\"}\n</code></pre>"},{"location":"faq/#whats-the-memory-footprint","title":"What's the memory footprint?","text":"<p>Formula: <pre><code>Memory \u2248 (queue_size \u00d7 avg_message_size \u00d7 3 queues) + JVM overhead\n</code></pre></p> <p>Examples:</p> <ul> <li>Queue: 10,000, Avg message: 2 KB \u2192 ~60 MB + overhead = ~100 MB</li> <li>Queue: 50,000, Avg message: 2 KB \u2192 ~300 MB + overhead = ~400 MB</li> </ul> <p>Recommendation: - Development: 1 GB heap - Production: 4 GB heap</p>"},{"location":"faq/#how-do-i-optimize-throughput","title":"How do I optimize throughput?","text":"<ol> <li> <p>Use Protobuf format:    <pre><code>\"otlp.message.format\": \"protobuf\"\n</code></pre></p> </li> <li> <p>Increase queue size:    <pre><code>\"otlp.message.queue.size\": \"50000\"\n</code></pre></p> </li> <li> <p>Optimize Kafka producer (<code>connect-distributed.properties</code>):    <pre><code>producer.linger.ms=10\nproducer.batch.size=32768\nproducer.compression.type=lz4\nproducer.acks=1\n</code></pre></p> </li> <li> <p>Increase topic partitions:    <pre><code>kafka-topics.sh --alter --topic otlp-traces --partitions 12\n</code></pre></p> </li> </ol>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#why-isnt-my-connector-appearing-in-the-plugin-list","title":"Why isn't my connector appearing in the plugin list?","text":"<p>Check:</p> <ol> <li>JAR is in the correct plugin directory</li> <li><code>plugin.path</code> is configured in <code>connect-distributed.properties</code></li> <li>Kafka Connect was restarted after installation</li> <li>JAR includes all dependencies</li> </ol> <p>Verify: <pre><code>ls -lh $KAFKA_HOME/plugins/kafka-connect-opentelemetry/\ncurl http://localhost:8083/connector-plugins | jq '.[] | select(.class | contains(\"OpenTelemetry\"))'\n</code></pre></p>"},{"location":"faq/#why-do-i-get-address-already-in-use-error","title":"Why do I get \"Address already in use\" error?","text":"<p>Cause: Ports 4317 or 4318 are already bound.</p> <p>Solution:</p> <ol> <li> <p>Find the conflicting process:    <pre><code>lsof -i :4317\nlsof -i :4318\n</code></pre></p> </li> <li> <p>Use different ports:    <pre><code>{\n  \"otlp.grpc.port\": \"14317\",\n  \"otlp.http.port\": \"14318\"\n}\n</code></pre></p> </li> </ol>"},{"location":"faq/#why-are-messages-being-dropped","title":"Why are messages being dropped?","text":"<p>Check JMX metrics: <pre><code># TracesDropped, MetricsDropped, LogsDropped\n</code></pre></p> <p>Causes: 1. Queue overflow (queue size too small) 2. Kafka throughput bottleneck 3. High incoming telemetry rate</p> <p>Solutions: 1. Increase <code>otlp.message.queue.size</code> 2. Optimize Kafka producer settings 3. Switch to Protobuf format 4. Scale Kafka brokers</p> <p>See Operational Runbook for detailed troubleshooting.</p>"},{"location":"faq/#how-do-i-test-the-otlp-endpoints","title":"How do I test the OTLP endpoints?","text":"<p>gRPC endpoint: <pre><code>grpcurl -plaintext localhost:4317 list\n\n# Should show:\n# opentelemetry.proto.collector.trace.v1.TraceService\n# opentelemetry.proto.collector.metrics.v1.MetricsService\n# opentelemetry.proto.collector.logs.v1.LogsService\n</code></pre></p> <p>HTTP endpoint: <pre><code>curl -v http://localhost:4318/v1/traces \\\n  -H \"Content-Type: application/x-protobuf\"\n\n# Should return 200 or 400\n</code></pre></p>"},{"location":"faq/#compatibility","title":"Compatibility","text":""},{"location":"faq/#does-this-work-with-kafka-2x","title":"Does this work with Kafka 2.x?","text":"<p>No, minimum Kafka version is 3.9.0. The connector uses APIs introduced in Kafka 3.x.</p>"},{"location":"faq/#does-this-work-with-java-8","title":"Does this work with Java 8?","text":"<p>No, minimum Java version is 11. The connector and its dependencies require Java 11+.</p>"},{"location":"faq/#does-this-work-with-kubernetes","title":"Does this work with Kubernetes?","text":"<p>Yes, deploy Kafka Connect in Kubernetes and include this connector in the plugin directory:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kafka-connect-plugins\ndata:\n  kafka-connect-opentelemetry-1.0.0.jar: |\n    # Base64-encoded JAR content\n</code></pre> <p>Or build a custom Docker image:</p> <pre><code>FROM confluentinc/cp-kafka-connect:7.5.0\n\nCOPY kafka-connect-opentelemetry-1.0.0-jar-with-dependencies.jar \\\n  /usr/share/confluent-hub-components/kafka-connect-opentelemetry/\n</code></pre>"},{"location":"faq/#does-this-work-with-docker","title":"Does this work with Docker?","text":"<p>Yes. Example <code>docker-compose.yml</code>:</p> <pre><code>version: '3.8'\nservices:\n  kafka-connect:\n    image: confluentinc/cp-kafka-connect:7.5.0\n    volumes:\n      - ./kafka-connect-opentelemetry-1.0.0-jar-with-dependencies.jar:/usr/share/confluent-hub-components/kafka-connect-opentelemetry/kafka-connect-opentelemetry-1.0.0.jar\n    ports:\n      - \"8083:8083\"  # Connect REST API\n      - \"4317:4317\"  # OTLP gRPC\n      - \"4318:4318\"  # OTLP HTTP\n</code></pre>"},{"location":"faq/#comparison-with-alternatives","title":"Comparison with Alternatives","text":""},{"location":"faq/#when-should-i-use-this-connector-vs-otel-collector","title":"When should I use this connector vs. OTEL Collector?","text":"<p>Use this connector when: - You need Kafka as central telemetry platform - You want durable buffering (Kafka topics) - You're building custom telemetry pipelines - You need fan-out to multiple consumers - You want to leverage Kafka Streams/ksqlDB</p> <p>Use OTEL Collector when: - You need direct export to 50+ backends - You require advanced transformations - You don't need Kafka in your architecture - You need sophisticated sampling/filtering</p> <p>Use both: Apps \u2192 Connector \u2192 Kafka \u2192 OTEL Collector \u2192 Backends</p>"},{"location":"faq/#how-does-this-compare-to-jaeger-kafka","title":"How does this compare to Jaeger Kafka?","text":"Feature This Connector Jaeger Kafka Protocol OTLP (all signals) Jaeger (traces only) Signal Types Traces + Metrics + Logs Traces only Format JSON or Protobuf Jaeger Protobuf Ecosystem OpenTelemetry Jaeger Flexibility High (all OTEL SDKs) Medium (Jaeger clients)"},{"location":"faq/#still-have-questions","title":"Still Have Questions?","text":"<ul> <li>GitHub Issues: Open an issue</li> <li>Slack Community: Join Conduktor Slack</li> <li>Documentation: Browse documentation</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will help you install, configure, and deploy your first Kafka Connect OpenTelemetry connector.</p>"},{"location":"getting-started/#overview","title":"Overview","text":"<p>The Kafka Connect OpenTelemetry Source Connector enables you to receive telemetry data from any OpenTelemetry-instrumented application and stream it directly into Apache Kafka topics. It acts as an OTLP receiver endpoint, supporting both gRPC and HTTP protocols, and automatically routes traces, metrics, and logs to separate topics.</p>"},{"location":"getting-started/#what-youll-learn","title":"What You'll Learn","text":"<p>In this section, you'll learn how to:</p> <ol> <li>Prerequisites - Verify your environment has the required dependencies</li> <li>Installation - Install the connector in your Kafka Connect cluster (see main README)</li> <li>Configuration - Configure the connector for your use case</li> <li>Quick Start - Deploy your first connector and verify it's working (see main README)</li> </ol>"},{"location":"getting-started/#deployment-options","title":"Deployment Options","text":"<p>Choose the deployment method that best fits your environment:</p>"},{"location":"getting-started/#distributed-mode-production","title":"Distributed Mode (Production)","text":"<p>Best for: - Production deployments - High availability requirements - Multiple connectors - Horizontal scaling</p> <p>Configuration: <pre><code># config/connect-distributed.properties\nplugin.path=/usr/local/share/kafka/plugins\n</code></pre></p>"},{"location":"getting-started/#standalone-mode-development","title":"Standalone Mode (Development)","text":"<p>Best for: - Local development - Testing - Single connector instances - Quick prototyping</p> <p>Configuration: <pre><code># config/connect-standalone.properties\nplugin.path=/usr/local/share/kafka/plugins\n</code></pre></p>"},{"location":"getting-started/#system-requirements","title":"System Requirements","text":""},{"location":"getting-started/#minimum-requirements","title":"Minimum Requirements","text":"<ul> <li>Java: 11 or higher</li> <li>Kafka: 3.9.0 or higher</li> <li>Memory: 1 GB RAM for connector</li> <li>Network: Ability to bind to ports 4317 (gRPC) and 4318 (HTTP)</li> </ul>"},{"location":"getting-started/#recommended-for-production","title":"Recommended for Production","text":"<ul> <li>Java: 17 (LTS)</li> <li>Kafka: Latest stable version</li> <li>Memory: 4 GB RAM for Kafka Connect worker</li> <li>CPU: 4+ cores</li> <li>Network: Low-latency connection to Kafka brokers</li> </ul>"},{"location":"getting-started/#support-matrix","title":"Support Matrix","text":"Component Minimum Version Recommended Version Tested Versions Java 11 17 11, 17, 21 Kafka 3.9.0 3.9.0+ 3.9.0 Maven 3.6+ 3.9+ 3.6, 3.8, 3.9 gRPC 1.59.0 1.59.0 1.59.0 Protobuf 3.25.0 3.25.0 3.25.0"},{"location":"getting-started/#quick-links","title":"Quick Links","text":""},{"location":"getting-started/#main-readme","title":"Main README","text":"<p>Complete documentation with installation, configuration, and usage examples.</p>"},{"location":"getting-started/#configuration-reference","title":"Configuration Reference","text":"<p>Detailed configuration options and examples.</p>"},{"location":"getting-started/#faq","title":"FAQ","text":"<p>Frequently asked questions and troubleshooting tips.</p>"},{"location":"getting-started/#changelog","title":"Changelog","text":"<p>Version history, new features, and bug fixes.</p>"},{"location":"getting-started/#before-you-begin","title":"Before You Begin","text":"<p>Check Your Environment</p> <p>Before proceeding, ensure you have:</p> <ul> <li> Java 11+ installed (<code>java -version</code>)</li> <li> Kafka 3.9.0+ running</li> <li> Access to build the connector (Maven 3.6+)</li> <li> Ports 4317 and 4318 available for OTLP receivers</li> <li> OpenTelemetry-instrumented applications to send data</li> </ul> <p>Understanding OTLP</p> <p>OpenTelemetry Protocol (OTLP) is the standard protocol for transmitting telemetry data (traces, metrics, logs) from instrumented applications to collectors. This connector implements OTLP receiver endpoints compatible with all OpenTelemetry SDKs.</p>"},{"location":"getting-started/#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TB\n    A[OpenTelemetry App] --&gt;|OTLP/gRPC:4317| B[gRPC Receiver]\n    A --&gt;|OTLP/HTTP:4318| C[HTTP Receiver]\n\n    B --&gt; D[Message Queue - Traces]\n    B --&gt; E[Message Queue - Metrics]\n    B --&gt; F[Message Queue - Logs]\n\n    C --&gt; D\n    C --&gt; E\n    C --&gt; F\n\n    D --&gt;|poll| G[Kafka Connect Task]\n    E --&gt;|poll| G\n    F --&gt;|poll| G\n\n    G --&gt;|produce| H[Kafka Topic: traces]\n    G --&gt;|produce| I[Kafka Topic: metrics]\n    G --&gt;|produce| J[Kafka Topic: logs]\n\n    style A fill:#3b82f6\n    style B fill:#f59e0b\n    style C fill:#f59e0b\n    style D fill:#10b981\n    style E fill:#10b981\n    style F fill:#10b981\n    style G fill:#ef4444\n    style H fill:#8b5cf6\n    style I fill:#8b5cf6\n    style J fill:#8b5cf6</code></pre>"},{"location":"getting-started/#installation-steps","title":"Installation Steps","text":""},{"location":"getting-started/#1-build-the-connector","title":"1. Build the Connector","text":"<pre><code>cd kafka-connect-opentelemetry\nmvn clean package\n</code></pre> <p>This creates <code>target/kafka-connect-opentelemetry-1.0.0-jar-with-dependencies.jar</code></p>"},{"location":"getting-started/#2-install-in-plugin-directory","title":"2. Install in Plugin Directory","text":"<pre><code># Create plugin directory\nmkdir -p /usr/local/share/kafka/plugins/kafka-connect-opentelemetry\n\n# Copy the JAR\ncp target/kafka-connect-opentelemetry-1.0.0-jar-with-dependencies.jar \\\n   /usr/local/share/kafka/plugins/kafka-connect-opentelemetry/\n</code></pre>"},{"location":"getting-started/#3-configure-kafka-connect","title":"3. Configure Kafka Connect","text":"<p>Ensure <code>plugin.path</code> in <code>connect-distributed.properties</code>:</p> <pre><code>plugin.path=/usr/local/share/kafka/plugins\n</code></pre>"},{"location":"getting-started/#4-restart-kafka-connect","title":"4. Restart Kafka Connect","text":"<pre><code># Restart to load the new plugin\nsystemctl restart kafka-connect\n# or\n$KAFKA_HOME/bin/connect-distributed.sh config/connect-distributed.properties\n</code></pre>"},{"location":"getting-started/#5-verify-installation","title":"5. Verify Installation","text":"<pre><code>curl http://localhost:8083/connector-plugins | jq '.[] | select(.class | contains(\"OpenTelemetry\"))'\n</code></pre> <p>Expected output: <pre><code>{\n  \"class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n  \"type\": \"source\",\n  \"version\": \"1.0.0\"\n}\n</code></pre></p>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Ready to configure? Continue with:</p> <ol> <li>Prerequisites - Verify your environment</li> <li>Configuration - Configure connector options</li> <li>Main README - Deploy your first connector</li> </ol> <p>Need help? Check our FAQ or open an issue.</p>"},{"location":"getting-started/configuration/","title":"Configuration Reference","text":"<p>Complete reference for all configuration options of the Kafka Connect OpenTelemetry Source Connector.</p>"},{"location":"getting-started/configuration/#quick-reference","title":"Quick Reference","text":""},{"location":"getting-started/configuration/#minimal-configuration","title":"Minimal Configuration","text":"<p>Only the connector class is required - all other settings have sensible defaults:</p> <pre><code>{\n  \"name\": \"otlp-connector\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n    \"tasks.max\": \"1\"\n  }\n}\n</code></pre> <p>This uses: - gRPC on port 4317 - HTTP on port 4318 - Topics: <code>otlp-traces</code>, <code>otlp-metrics</code>, <code>otlp-logs</code> - JSON output format - 10,000 message queue size per signal type</p>"},{"location":"getting-started/configuration/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"getting-started/configuration/#required-parameters","title":"Required Parameters","text":"Parameter Type Description <code>connector.class</code> string Must be <code>io.conduktor.connect.otel.OpenTelemetrySourceConnector</code> <code>tasks.max</code> int Must be <code>1</code> (connector only supports single task)"},{"location":"getting-started/configuration/#otlp-receiver-configuration","title":"OTLP Receiver Configuration","text":"Parameter Type Default Description <code>otlp.grpc.enabled</code> boolean <code>true</code> Enable OTLP gRPC receiver <code>otlp.grpc.port</code> int <code>4317</code> Port for OTLP gRPC receiver (standard OTLP port) <code>otlp.http.enabled</code> boolean <code>true</code> Enable OTLP HTTP receiver <code>otlp.http.port</code> int <code>4318</code> Port for OTLP HTTP receiver (standard OTLP port) <code>otlp.bind.address</code> string <code>0.0.0.0</code> Bind address for OTLP receivers (use <code>127.0.0.1</code> for localhost only) <p>At Least One Protocol Required</p> <p>You must enable at least one protocol (gRPC or HTTP). Setting both to <code>false</code> will cause the connector to fail.</p>"},{"location":"getting-started/configuration/#kafka-topic-configuration","title":"Kafka Topic Configuration","text":"Parameter Type Default Description <code>kafka.topic.traces</code> string <code>otlp-traces</code> Kafka topic for trace data (OTLP <code>TracesData</code>) <code>kafka.topic.metrics</code> string <code>otlp-metrics</code> Kafka topic for metric data (OTLP <code>MetricsData</code>) <code>kafka.topic.logs</code> string <code>otlp-logs</code> Kafka topic for log data (OTLP <code>LogsData</code>) <p>Topic Naming Convention</p> <p>Use descriptive topic names that include: - Signal type (traces/metrics/logs) - Environment (prod/staging/dev) - Application or team name</p> <p>Examples: <code>prod-checkout-traces</code>, <code>staging-payment-metrics</code>, <code>dev-analytics-logs</code></p>"},{"location":"getting-started/configuration/#message-format-configuration","title":"Message Format Configuration","text":"Parameter Type Default Description <code>otlp.message.format</code> string <code>json</code> Output format: <code>json</code> or <code>protobuf</code> <code>otlp.message.queue.size</code> int <code>10000</code> Maximum size of message buffer queue per signal type"},{"location":"getting-started/configuration/#format-comparison","title":"Format Comparison","text":"Aspect JSON Protobuf Size Larger (3-5x) Smaller (binary) Readability Human-readable Base64-encoded binary Debugging Easy to inspect Requires decoding Performance Slower serialization Faster serialization Downstream Easy JSON processing Requires protobuf decoder Best for Development, debugging Production, high volume"},{"location":"getting-started/configuration/#tls-configuration-planned","title":"TLS Configuration (Planned)","text":"<p>Coming Soon</p> <p>TLS support is planned for a future release.</p> Parameter Type Default Description <code>otlp.tls.enabled</code> boolean <code>false</code> Enable TLS for OTLP receivers <code>otlp.tls.cert.path</code> string - Path to TLS certificate file (PEM format) <code>otlp.tls.key.path</code> string - Path to TLS private key file (PEM format)"},{"location":"getting-started/configuration/#configuration-examples","title":"Configuration Examples","text":""},{"location":"getting-started/configuration/#production-configuration","title":"Production Configuration","text":"<p>High-throughput production setup with protobuf format:</p> <pre><code>{\n  \"name\": \"otlp-production\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n    \"tasks.max\": \"1\",\n\n    \"otlp.grpc.enabled\": \"true\",\n    \"otlp.grpc.port\": \"4317\",\n    \"otlp.http.enabled\": \"true\",\n    \"otlp.http.port\": \"4318\",\n    \"otlp.bind.address\": \"0.0.0.0\",\n\n    \"kafka.topic.traces\": \"prod-otlp-traces\",\n    \"kafka.topic.metrics\": \"prod-otlp-metrics\",\n    \"kafka.topic.logs\": \"prod-otlp-logs\",\n\n    \"otlp.message.format\": \"protobuf\",\n    \"otlp.message.queue.size\": \"50000\"\n  }\n}\n</code></pre>"},{"location":"getting-started/configuration/#development-configuration","title":"Development Configuration","text":"<p>Development setup with JSON format for easy debugging:</p> <pre><code>{\n  \"name\": \"otlp-dev\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n    \"tasks.max\": \"1\",\n\n    \"otlp.grpc.enabled\": \"true\",\n    \"otlp.grpc.port\": \"4317\",\n    \"otlp.http.enabled\": \"true\",\n    \"otlp.http.port\": \"4318\",\n    \"otlp.bind.address\": \"127.0.0.1\",\n\n    \"kafka.topic.traces\": \"dev-traces\",\n    \"kafka.topic.metrics\": \"dev-metrics\",\n    \"kafka.topic.logs\": \"dev-logs\",\n\n    \"otlp.message.format\": \"json\",\n    \"otlp.message.queue.size\": \"5000\"\n  }\n}\n</code></pre>"},{"location":"getting-started/configuration/#grpc-only-configuration","title":"gRPC Only Configuration","text":"<p>Accept only gRPC connections (disable HTTP):</p> <pre><code>{\n  \"name\": \"otlp-grpc-only\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n    \"tasks.max\": \"1\",\n\n    \"otlp.grpc.enabled\": \"true\",\n    \"otlp.grpc.port\": \"4317\",\n    \"otlp.http.enabled\": \"false\",\n\n    \"kafka.topic.traces\": \"otlp-traces\",\n    \"kafka.topic.metrics\": \"otlp-metrics\",\n    \"kafka.topic.logs\": \"otlp-logs\",\n\n    \"otlp.message.format\": \"json\"\n  }\n}\n</code></pre>"},{"location":"getting-started/configuration/#http-only-configuration","title":"HTTP Only Configuration","text":"<p>Accept only HTTP connections (disable gRPC):</p> <pre><code>{\n  \"name\": \"otlp-http-only\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n    \"tasks.max\": \"1\",\n\n    \"otlp.grpc.enabled\": \"false\",\n    \"otlp.http.enabled\": \"true\",\n    \"otlp.http.port\": \"4318\",\n\n    \"kafka.topic.traces\": \"otlp-traces\",\n    \"kafka.topic.metrics\": \"otlp-metrics\",\n    \"kafka.topic.logs\": \"otlp-logs\",\n\n    \"otlp.message.format\": \"json\"\n  }\n}\n</code></pre>"},{"location":"getting-started/configuration/#custom-ports-configuration","title":"Custom Ports Configuration","text":"<p>Use non-standard ports (e.g., when standard ports are in use):</p> <pre><code>{\n  \"name\": \"otlp-custom-ports\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n    \"tasks.max\": \"1\",\n\n    \"otlp.grpc.enabled\": \"true\",\n    \"otlp.grpc.port\": \"14317\",\n    \"otlp.http.enabled\": \"true\",\n    \"otlp.http.port\": \"14318\",\n\n    \"kafka.topic.traces\": \"otlp-traces\",\n    \"kafka.topic.metrics\": \"otlp-metrics\",\n    \"kafka.topic.logs\": \"otlp-logs\"\n  }\n}\n</code></pre>"},{"location":"getting-started/configuration/#multi-environment-setup","title":"Multi-Environment Setup","text":"<p>Separate configurations for different environments:</p> ProductionStagingDevelopment <pre><code>{\n  \"name\": \"otlp-prod\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n    \"tasks.max\": \"1\",\n\n    \"otlp.grpc.port\": \"4317\",\n    \"otlp.http.port\": \"4318\",\n\n    \"kafka.topic.traces\": \"prod-traces\",\n    \"kafka.topic.metrics\": \"prod-metrics\",\n    \"kafka.topic.logs\": \"prod-logs\",\n\n    \"otlp.message.format\": \"protobuf\",\n    \"otlp.message.queue.size\": \"50000\"\n  }\n}\n</code></pre> <pre><code>{\n  \"name\": \"otlp-staging\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n    \"tasks.max\": \"1\",\n\n    \"otlp.grpc.port\": \"5317\",\n    \"otlp.http.port\": \"5318\",\n\n    \"kafka.topic.traces\": \"staging-traces\",\n    \"kafka.topic.metrics\": \"staging-metrics\",\n    \"kafka.topic.logs\": \"staging-logs\",\n\n    \"otlp.message.format\": \"json\",\n    \"otlp.message.queue.size\": \"20000\"\n  }\n}\n</code></pre> <pre><code>{\n  \"name\": \"otlp-dev\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n    \"tasks.max\": \"1\",\n\n    \"otlp.grpc.port\": \"6317\",\n    \"otlp.http.port\": \"6318\",\n\n    \"kafka.topic.traces\": \"dev-traces\",\n    \"kafka.topic.metrics\": \"dev-metrics\",\n    \"kafka.topic.logs\": \"dev-logs\",\n\n    \"otlp.message.format\": \"json\",\n    \"otlp.message.queue.size\": \"5000\"\n  }\n}\n</code></pre>"},{"location":"getting-started/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"getting-started/configuration/#queue-size-recommendations","title":"Queue Size Recommendations","text":"<p>Choose queue size based on your expected throughput and latency requirements:</p> Throughput Queue Size Memory Impact Use Case Low (&lt; 100 msg/s) 1,000 - 5,000 ~10-50 MB Development, testing Medium (100-1,000 msg/s) 10,000 ~100 MB Standard production High (1,000-5,000 msg/s) 20,000 - 50,000 ~200-500 MB High-volume production Very High (&gt; 5,000 msg/s) 50,000 - 100,000 ~500 MB - 1 GB Extreme throughput <p>Memory Impact</p> <p>Memory usage = <code>queue_size \u00d7 avg_message_size \u00d7 3 queues</code></p> <p>Example: 50,000 queue \u00d7 2 KB avg \u00d7 3 = ~300 MB</p>"},{"location":"getting-started/configuration/#format-selection-guide","title":"Format Selection Guide","text":"Scenario Recommended Format Reason Development JSON Easy debugging, human-readable Testing JSON Simple validation, inspection Production (low volume) JSON Flexibility, easier troubleshooting Production (high volume) Protobuf Smaller size, better performance Compliance/Audit JSON Long-term readability Real-time analytics Protobuf Lower latency, higher throughput"},{"location":"getting-started/configuration/#deployment-workflow","title":"Deployment Workflow","text":""},{"location":"getting-started/configuration/#1-create-configuration-file","title":"1. Create Configuration File","text":"<pre><code>cat &gt; otlp-connector.json &lt;&lt;EOF\n{\n  \"name\": \"otlp-source\",\n  \"config\": {\n    \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n    \"tasks.max\": \"1\",\n    \"otlp.grpc.port\": \"4317\",\n    \"otlp.http.port\": \"4318\",\n    \"kafka.topic.traces\": \"otlp-traces\",\n    \"kafka.topic.metrics\": \"otlp-metrics\",\n    \"kafka.topic.logs\": \"otlp-logs\",\n    \"otlp.message.format\": \"json\",\n    \"otlp.message.queue.size\": \"10000\"\n  }\n}\nEOF\n</code></pre>"},{"location":"getting-started/configuration/#2-deploy-connector","title":"2. Deploy Connector","text":"<pre><code>curl -X POST http://localhost:8083/connectors \\\n  -H \"Content-Type: application/json\" \\\n  -d @otlp-connector.json\n</code></pre>"},{"location":"getting-started/configuration/#3-verify-deployment","title":"3. Verify Deployment","text":"<pre><code># Check connector status\ncurl http://localhost:8083/connectors/otlp-source/status | jq .\n\n# Expected output:\n# {\n#   \"name\": \"otlp-source\",\n#   \"connector\": {\n#     \"state\": \"RUNNING\",\n#     \"worker_id\": \"...\"\n#   },\n#   \"tasks\": [\n#     {\n#       \"id\": 0,\n#       \"state\": \"RUNNING\",\n#       \"worker_id\": \"...\"\n#     }\n#   ]\n# }\n</code></pre>"},{"location":"getting-started/configuration/#4-test-otlp-endpoints","title":"4. Test OTLP Endpoints","text":"<pre><code># Test gRPC endpoint\ngrpcurl -plaintext localhost:4317 list\n\n# Test HTTP endpoint\ncurl -v http://localhost:4318/v1/traces\n</code></pre>"},{"location":"getting-started/configuration/#configuration-updates","title":"Configuration Updates","text":""},{"location":"getting-started/configuration/#update-running-connector","title":"Update Running Connector","text":"<p>To update configuration without recreating:</p> <pre><code># 1. Update configuration file\ncat &gt; updated-config.json &lt;&lt;EOF\n{\n  \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n  \"tasks.max\": \"1\",\n  \"otlp.message.queue.size\": \"20000\",\n  \"otlp.message.format\": \"protobuf\"\n}\nEOF\n\n# 2. Apply update\ncurl -X PUT http://localhost:8083/connectors/otlp-source/config \\\n  -H \"Content-Type: application/json\" \\\n  -d @updated-config.json\n\n# 3. Verify update\ncurl http://localhost:8083/connectors/otlp-source/status\n</code></pre>"},{"location":"getting-started/configuration/#configuration-changes-requiring-restart","title":"Configuration Changes Requiring Restart","text":"<p>The following configuration changes require a connector restart:</p> <ul> <li><code>otlp.grpc.enabled</code></li> <li><code>otlp.grpc.port</code></li> <li><code>otlp.http.enabled</code></li> <li><code>otlp.http.port</code></li> <li><code>otlp.bind.address</code></li> </ul> <p>The connector will automatically restart when you update these via PUT.</p>"},{"location":"getting-started/configuration/#configuration-changes-without-restart","title":"Configuration Changes Without Restart","text":"<p>These can be changed without restart (applied to new messages only):</p> <ul> <li><code>kafka.topic.traces</code></li> <li><code>kafka.topic.metrics</code></li> <li><code>kafka.topic.logs</code></li> <li><code>otlp.message.format</code></li> <li><code>otlp.message.queue.size</code></li> </ul>"},{"location":"getting-started/configuration/#validation","title":"Validation","text":"<p>The connector validates configuration on startup:</p>"},{"location":"getting-started/configuration/#common-validation-errors","title":"Common Validation Errors","text":"Error Message Cause Solution \"Invalid value for otlp.grpc.port\" Port out of range Use port 1024-65535 \"Invalid value for otlp.message.format\" Unknown format Use <code>json</code> or <code>protobuf</code> \"At least one protocol must be enabled\" Both protocols disabled Enable gRPC or HTTP \"Invalid value for otlp.message.queue.size\" Queue size &lt; 1 Use positive integer"},{"location":"getting-started/configuration/#validate-before-deployment","title":"Validate Before Deployment","text":"<p>Use Kafka Connect's validation endpoint:</p> <pre><code>curl -X PUT http://localhost:8083/connector-plugins/io.conduktor.connect.otel.OpenTelemetrySourceConnector/config/validate \\\n  -H \"Content-Type: application/json\" \\\n  -d @otlp-connector.json\n</code></pre>"},{"location":"getting-started/configuration/#best-practices","title":"Best Practices","text":""},{"location":"getting-started/configuration/#production-checklist","title":"Production Checklist","text":"<ul> <li> Use <code>protobuf</code> format for high volume</li> <li> Set <code>otlp.message.queue.size</code> based on throughput</li> <li> Use descriptive topic names with environment prefix</li> <li> Pre-create Kafka topics with appropriate partitions</li> <li> Configure JMX monitoring</li> <li> Set up alerts for queue utilization</li> <li> Document connector configuration in version control</li> <li> Test with realistic load before production</li> </ul>"},{"location":"getting-started/configuration/#security-considerations","title":"Security Considerations","text":"<ul> <li>Use <code>otlp.bind.address: \"127.0.0.1\"</code> if receiving telemetry from localhost only</li> <li>Plan for TLS when feature is released</li> <li>Secure Kafka Connect REST API with authentication</li> <li>Restrict network access to OTLP ports (4317, 4318)</li> <li>Use Kafka ACLs to control topic access</li> </ul>"},{"location":"getting-started/configuration/#troubleshooting-configuration","title":"Troubleshooting Configuration","text":""},{"location":"getting-started/configuration/#port-already-in-use","title":"Port Already in Use","text":"<pre><code># Find what's using the port\nlsof -i :4317\n\n# Use different port\n\"otlp.grpc.port\": \"14317\"\n</code></pre>"},{"location":"getting-started/configuration/#queue-overflow","title":"Queue Overflow","text":"<pre><code># Check JMX metrics for drops\njconsole # Navigate to TracesDropped/MetricsDropped/LogsDropped\n\n# Increase queue size\n\"otlp.message.queue.size\": \"50000\"\n</code></pre>"},{"location":"getting-started/configuration/#wrong-message-format","title":"Wrong Message Format","text":"<pre><code># Check what format downstream consumers expect\n# JSON: Easier to process with Kafka Streams, ksqlDB\n# Protobuf: Requires protobuf decoder\n\n# Change format\n\"otlp.message.format\": \"json\"  # or \"protobuf\"\n</code></pre>"},{"location":"getting-started/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Operational Runbook - Monitoring and troubleshooting</li> <li>FAQ - Common questions</li> <li>Main README - Examples and usage</li> </ul> <p>Need help? Open an issue or join our Slack.</p>"},{"location":"getting-started/prerequisites/","title":"Prerequisites","text":"<p>Before installing the Kafka Connect OpenTelemetry connector, ensure your environment meets the following requirements.</p>"},{"location":"getting-started/prerequisites/#required-software","title":"Required Software","text":""},{"location":"getting-started/prerequisites/#java-development-kit-jdk","title":"Java Development Kit (JDK)","text":"<p>Minimum Version: Java 11 Recommended: Java 17 (LTS)</p> Check Java VersionInstall Java (Ubuntu/Debian)Install Java (macOS)Install Java (RHEL/CentOS) <pre><code>java -version\n</code></pre> <p>Expected output: <pre><code>openjdk version \"17.0.9\" 2023-10-17 LTS\nOpenJDK Runtime Environment (build 17.0.9+9-LTS)\n</code></pre></p> <pre><code>sudo apt update\nsudo apt install openjdk-17-jdk\n</code></pre> <pre><code>brew install openjdk@17\n</code></pre> <pre><code>sudo yum install java-17-openjdk-devel\n</code></pre>"},{"location":"getting-started/prerequisites/#apache-kafka","title":"Apache Kafka","text":"<p>Minimum Version: 3.9.0 Download: Apache Kafka Downloads</p> Verify Kafka InstallationQuick Kafka Setup (Local) <pre><code>kafka-topics.sh --version\n</code></pre> <p>Expected output: <pre><code>3.9.0 (Commit:...)\n</code></pre></p> <pre><code># Download Kafka\nwget https://downloads.apache.org/kafka/3.9.0/kafka_2.13-3.9.0.tgz\ntar -xzf kafka_2.13-3.9.0.tgz\ncd kafka_2.13-3.9.0\n\n# Start Kafka (KRaft mode)\nKAFKA_CLUSTER_ID=\"$(bin/kafka-storage.sh random-uuid)\"\nbin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties\nbin/kafka-server-start.sh config/kraft/server.properties\n</code></pre>"},{"location":"getting-started/prerequisites/#maven-for-building-from-source","title":"Maven (for building from source)","text":"<p>Minimum Version: 3.6+ Recommended: 3.9+</p> <pre><code>mvn --version\n</code></pre> <p>Expected output: <pre><code>Apache Maven 3.9.5\nMaven home: /usr/share/maven\nJava version: 17.0.9\n</code></pre></p>"},{"location":"getting-started/prerequisites/#opentelemetry-applications","title":"OpenTelemetry Applications","text":"<p>You'll need applications instrumented with OpenTelemetry SDKs to send telemetry data to the connector.</p>"},{"location":"getting-started/prerequisites/#verify-otlp-support","title":"Verify OTLP Support","text":"<p>Most OpenTelemetry SDKs support OTLP out of the box:</p> Language SDK OTLP Support Java opentelemetry-java \u2705 Built-in Python opentelemetry-python \u2705 Built-in Go opentelemetry-go \u2705 Built-in Node.js opentelemetry-js \u2705 Built-in .NET opentelemetry-dotnet \u2705 Built-in Ruby opentelemetry-ruby \u2705 Built-in"},{"location":"getting-started/prerequisites/#test-otlp-connectivity","title":"Test OTLP Connectivity","text":"<p>Install OpenTelemetry CLI tool for testing:</p> <pre><code># Using Docker\ndocker run --rm -it \\\n  otel/opentelemetry-collector-contrib:latest \\\n  --config=/dev/null\n\n# Or install locally\ngo install go.opentelemetry.io/collector/cmd/otelcol@latest\n</code></pre>"},{"location":"getting-started/prerequisites/#network-requirements","title":"Network Requirements","text":""},{"location":"getting-started/prerequisites/#port-availability","title":"Port Availability","text":"<p>The connector requires these ports to be available:</p> Protocol Port Purpose Configurable OTLP gRPC 4317 Receive OTLP via gRPC Yes (<code>otlp.grpc.port</code>) OTLP HTTP 4318 Receive OTLP via HTTP Yes (<code>otlp.http.port</code>) <p>Check Port Availability</p> <pre><code># Check if ports are available\nnetstat -an | grep 4317\nnetstat -an | grep 4318\n\n# Or use lsof\nlsof -i :4317\nlsof -i :4318\n</code></pre> <p>If ports are in use, you can configure different ports in the connector configuration.</p>"},{"location":"getting-started/prerequisites/#firewall-configuration","title":"Firewall Configuration","text":"<p>If running behind a firewall, ensure inbound access to OTLP ports:</p> <pre><code># Allow OTLP gRPC (4317)\nsudo ufw allow 4317/tcp\n\n# Allow OTLP HTTP (4318)\nsudo ufw allow 4318/tcp\n</code></pre>"},{"location":"getting-started/prerequisites/#test-otlp-endpoint","title":"Test OTLP Endpoint","text":"<p>After starting the connector, test connectivity:</p> gRPC (Port 4317)HTTP (Port 4318) <pre><code># Using grpcurl\ngrpcurl -plaintext localhost:4317 list\n\n# Should show OpenTelemetry services:\n# opentelemetry.proto.collector.trace.v1.TraceService\n# opentelemetry.proto.collector.metrics.v1.MetricsService\n# opentelemetry.proto.collector.logs.v1.LogsService\n</code></pre> <pre><code># Test HTTP endpoint\ncurl -v http://localhost:4318/v1/traces \\\n  -H \"Content-Type: application/x-protobuf\" \\\n  -d \"\"\n\n# Should return 200 or 400 (empty body)\n</code></pre>"},{"location":"getting-started/prerequisites/#kafka-connect-setup","title":"Kafka Connect Setup","text":""},{"location":"getting-started/prerequisites/#distributed-mode-recommended-for-production","title":"Distributed Mode (Recommended for Production)","text":"<p>Ensure Kafka Connect is running in distributed mode:</p> <pre><code># Check if Connect is running\ncurl http://localhost:8083/\n</code></pre> <p>Expected response: <pre><code>{\n  \"version\": \"3.9.0\",\n  \"commit\": \"...\",\n  \"kafka_cluster_id\": \"...\"\n}\n</code></pre></p>"},{"location":"getting-started/prerequisites/#internal-topics-configuration","title":"Internal Topics Configuration","text":"<p>Kafka Connect in distributed mode requires three internal topics:</p> <pre><code># In connect-distributed.properties\noffset.storage.topic=connect-offsets\noffset.storage.replication.factor=3\noffset.storage.partitions=25\n\nconfig.storage.topic=connect-configs\nconfig.storage.replication.factor=3\nconfig.storage.partitions=1\n\nstatus.storage.topic=connect-status\nstatus.storage.replication.factor=3\nstatus.storage.partitions=5\n</code></pre>"},{"location":"getting-started/prerequisites/#producer-configuration","title":"Producer Configuration","text":"<p>Configure producer settings for source connectors in <code>connect-distributed.properties</code>:</p> <pre><code># Optimize for throughput\nproducer.linger.ms=10\nproducer.batch.size=32768\nproducer.compression.type=lz4\nproducer.acks=1\n</code></pre>"},{"location":"getting-started/prerequisites/#plugin-directory","title":"Plugin Directory","text":"<p>Verify the plugin path is configured:</p> <pre><code># Check connect-distributed.properties\ngrep plugin.path $KAFKA_HOME/config/connect-distributed.properties\n</code></pre> <p>Expected output: <pre><code>plugin.path=/usr/local/share/kafka/plugins\n</code></pre></p> <p>Plugin Path Must Exist</p> <p>The plugin directory must exist and have proper permissions: <pre><code>sudo mkdir -p /usr/local/share/kafka/plugins\nsudo chown -R $USER:$USER /usr/local/share/kafka/plugins\n</code></pre></p>"},{"location":"getting-started/prerequisites/#create-kafka-topics","title":"Create Kafka Topics","text":"<p>Pre-create Kafka topics for telemetry data:</p> <pre><code># Create traces topic\nkafka-topics.sh --bootstrap-server localhost:9092 \\\n  --create --topic otlp-traces \\\n  --partitions 6 \\\n  --replication-factor 3\n\n# Create metrics topic\nkafka-topics.sh --bootstrap-server localhost:9092 \\\n  --create --topic otlp-metrics \\\n  --partitions 6 \\\n  --replication-factor 3\n\n# Create logs topic\nkafka-topics.sh --bootstrap-server localhost:9092 \\\n  --create --topic otlp-logs \\\n  --partitions 6 \\\n  --replication-factor 3\n</code></pre> <p>Topic Partitioning</p> <ul> <li>More partitions = higher parallelism for consumers</li> <li>Recommended: 6-12 partitions per topic for production</li> <li>Adjust based on expected throughput</li> </ul>"},{"location":"getting-started/prerequisites/#resource-requirements","title":"Resource Requirements","text":""},{"location":"getting-started/prerequisites/#minimum-resources","title":"Minimum Resources","text":"<p>For development/testing:</p> Resource Requirement CPU 2 cores Memory 1 GB for connector Disk 100 MB for JAR files Network 10 Mbps"},{"location":"getting-started/prerequisites/#production-resources","title":"Production Resources","text":"<p>For production deployments:</p> Resource Requirement CPU 4+ cores Memory 4 GB for Kafka Connect worker Disk 1 GB (for JARs + logs) Network 100+ Mbps"},{"location":"getting-started/prerequisites/#memory-configuration","title":"Memory Configuration","text":"<p>Configure heap size for Kafka Connect:</p> <pre><code># In connect-distributed.sh or systemd service\nexport KAFKA_HEAP_OPTS=\"-Xms4G -Xmx4G\"\n</code></pre> <p>Memory Sizing</p> <p>Memory requirements scale with: - Queue size (<code>otlp.message.queue.size</code>) - Average message size - Throughput (messages per second)</p> <p>Formula: Memory \u2248 (queue_size \u00d7 avg_message_size \u00d7 3) \u00d7 3 queues</p>"},{"location":"getting-started/prerequisites/#security-configuration","title":"Security Configuration","text":""},{"location":"getting-started/prerequisites/#secure-jmx-access","title":"Secure JMX Access","text":"<p>For production, enable JMX authentication:</p> <pre><code># Create password file\necho \"admin changeit\" &gt; /etc/kafka/jmx.password\nchmod 600 /etc/kafka/jmx.password\n\n# Create access file\necho \"admin readwrite\" &gt; /etc/kafka/jmx.access\nchmod 644 /etc/kafka/jmx.access\n\n# Configure Kafka Connect\nexport KAFKA_JMX_OPTS=\"-Dcom.sun.management.jmxremote \\\n  -Dcom.sun.management.jmxremote.authenticate=true \\\n  -Dcom.sun.management.jmxremote.password.file=/etc/kafka/jmx.password \\\n  -Dcom.sun.management.jmxremote.access.file=/etc/kafka/jmx.access \\\n  -Dcom.sun.management.jmxremote.ssl=true\"\n</code></pre> <p>Never Run JMX Without Authentication in Production</p> <p>Default JMX configuration with <code>authenticate=false</code> exposes your connector to unauthorized access.</p>"},{"location":"getting-started/prerequisites/#tls-for-otlp-planned-feature","title":"TLS for OTLP (Planned Feature)","text":"<p>Future versions will support TLS for OTLP receivers:</p> <pre><code>{\n  \"otlp.tls.enabled\": \"true\",\n  \"otlp.tls.cert.path\": \"/etc/kafka/certs/server.crt\",\n  \"otlp.tls.key.path\": \"/etc/kafka/certs/server.key\"\n}\n</code></pre>"},{"location":"getting-started/prerequisites/#optional-tools","title":"Optional Tools","text":""},{"location":"getting-started/prerequisites/#monitoring-tools","title":"Monitoring Tools","text":"<p>For production deployments, consider installing:</p> <ul> <li>JMX Monitoring: JConsole, VisualVM, or JMX Exporter</li> <li>Prometheus: For metrics collection</li> <li>Grafana: For dashboards</li> <li>Loki/ELK: For log aggregation</li> </ul>"},{"location":"getting-started/prerequisites/#development-tools","title":"Development Tools","text":"<p>For connector development:</p> <ul> <li>Git: Version control</li> <li>Docker: Containerized Kafka setup</li> <li>curl/jq: API testing and JSON parsing</li> <li>grpcurl: gRPC endpoint testing</li> </ul>"},{"location":"getting-started/prerequisites/#otlp-testing-tools","title":"OTLP Testing Tools","text":"<pre><code># Install grpcurl for gRPC testing\nbrew install grpcurl  # macOS\n# or\ngo install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest\n\n# Install otel-cli for sending test data\ngo install github.com/equinix-labs/otel-cli@latest\n</code></pre>"},{"location":"getting-started/prerequisites/#verification-checklist","title":"Verification Checklist","text":"<p>Before proceeding to installation, verify:</p> <ul> <li> Java 11+ is installed and <code>java -version</code> works</li> <li> Kafka 3.9.0+ is running</li> <li> Kafka Connect REST API is accessible at <code>http://localhost:8083/</code></li> <li> Plugin directory exists and is writable</li> <li> Maven 3.6+ is installed (for building from source)</li> <li> Ports 4317 and 4318 are available</li> <li> Kafka topics for traces, metrics, and logs are created</li> <li> OpenTelemetry applications are ready to send data</li> </ul>"},{"location":"getting-started/prerequisites/#troubleshooting-prerequisites","title":"Troubleshooting Prerequisites","text":""},{"location":"getting-started/prerequisites/#java-version-issues","title":"Java Version Issues","text":"<p>Problem: Wrong Java version</p> <pre><code># Check all Java installations\nls -la /usr/lib/jvm/\n\n# Set JAVA_HOME\nexport JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64\nexport PATH=$JAVA_HOME/bin:$PATH\n</code></pre>"},{"location":"getting-started/prerequisites/#kafka-not-running","title":"Kafka Not Running","text":"<p>Problem: Kafka Connect not accessible</p> <pre><code># Check Kafka Connect logs\ntail -f $KAFKA_HOME/logs/connect.log\n\n# Restart Kafka Connect\n$KAFKA_HOME/bin/connect-distributed.sh config/connect-distributed.properties\n</code></pre>"},{"location":"getting-started/prerequisites/#port-conflicts","title":"Port Conflicts","text":"<p>Problem: Ports 4317 or 4318 already in use</p> <pre><code># Find process using the port\nlsof -i :4317\nlsof -i :4318\n\n# Kill the process or use different ports\n# Configure custom ports in connector config:\n# \"otlp.grpc.port\": \"14317\"\n# \"otlp.http.port\": \"14318\"\n</code></pre>"},{"location":"getting-started/prerequisites/#next-steps","title":"Next Steps","text":"<p>Once all prerequisites are met:</p> <ol> <li>Installation - Install the connector</li> <li>Configuration - Configure connector options</li> <li>Quick Start - Deploy your first connector</li> </ol> <p>Need help? Check our FAQ or open an issue.</p>"},{"location":"operations/RUNBOOK/","title":"OpenTelemetry Source Connector - Operational Runbook","text":"<p>This runbook provides operational guidance for monitoring, troubleshooting, and maintaining the OpenTelemetry Source Connector in production.</p>"},{"location":"operations/RUNBOOK/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Incident Response Decision Tree</li> <li>Monitoring</li> <li>Common Issues</li> <li>Performance Tuning</li> <li>Troubleshooting</li> <li>Recovery Procedures</li> </ul>"},{"location":"operations/RUNBOOK/#incident-response-decision-tree","title":"Incident Response Decision Tree","text":"<p>Use this decision tree when an alert fires or an issue is reported:</p> <pre><code>START: Alert or Issue Reported\n\u2502\n\u251c\u2500 Is connector in RUNNING state?\n\u2502  \u2502  curl http://localhost:8083/connectors/&lt;name&gt;/status | jq '.connector.state'\n\u2502  \u2502\n\u2502  \u2514\u2500 NO \u2192 Go to [Connector Not Running](#issue-connector-not-running)\n\u2502  \u2514\u2500 YES \u2192 Continue \u2193\n\u2502\n\u251c\u2500 Are OTLP receivers listening?\n\u2502  \u2502  netstat -an | grep 4317 (gRPC)\n\u2502  \u2502  netstat -an | grep 4318 (HTTP)\n\u2502  \u2502\n\u2502  \u2514\u2500 NO \u2192 Go to [Receivers Not Started](#issue-1-otlp-receivers-not-listening)\n\u2502  \u2514\u2500 YES \u2192 Continue \u2193\n\u2502\n\u251c\u2500 Are messages being received? (TotalMessagesReceived increasing)\n\u2502  \u2502  Check JMX: io.conduktor.connect.otel:*/TotalMessagesReceived\n\u2502  \u2502\n\u2502  \u2514\u2500 NO \u2192 Go to [No Messages Received](#issue-2-no-messages-received)\n\u2502  \u2514\u2500 YES \u2192 Continue \u2193\n\u2502\n\u251c\u2500 Are queues near capacity? (MaxQueueUtilizationPercent &gt; 80%)\n\u2502  \u2502  Check JMX: io.conduktor.connect.otel:*/MaxQueueUtilizationPercent\n\u2502  \u2502\n\u2502  \u2514\u2500 YES \u2192 Go to [High Message Drop Rate](#issue-3-high-message-drop-rate)\n\u2502  \u2514\u2500 NO \u2192 Continue \u2193\n\u2502\n\u251c\u2500 Is Kafka write lagging? (RecordsProduced &lt;&lt; TotalMessagesReceived)\n\u2502  \u2502  Check lag: TotalMessagesReceived - RecordsProduced &gt; 10000\n\u2502  \u2502\n\u2502  \u2514\u2500 YES \u2192 Go to [Processing Lag](#issue-4-processing-lag-building-up)\n\u2502  \u2514\u2500 NO \u2192 Continue \u2193\n\u2502\n\u2514\u2500 Check logs for errors\n   \u2502  grep \"ERROR\\|WARN\" $KAFKA_HOME/logs/connect.log | tail -50\n   \u2502\n   \u2514\u2500 Errors found \u2192 Match error to [Common Issues](#common-issues)\n   \u2514\u2500 No errors \u2192 Monitor, escalate if issue persists\n</code></pre>"},{"location":"operations/RUNBOOK/#quick-commands-reference","title":"Quick Commands Reference","text":"<pre><code># Check connector status\ncurl -s http://localhost:8083/connectors/&lt;name&gt;/status | jq .\n\n# Restart connector\ncurl -X POST http://localhost:8083/connectors/&lt;name&gt;/restart\n\n# Restart specific task\ncurl -X POST http://localhost:8083/connectors/&lt;name&gt;/tasks/0/restart\n\n# Check recent logs\ntail -100 $KAFKA_HOME/logs/connect.log | grep -E \"OpenTelemetry|ERROR|WARN\"\n\n# Check OTLP endpoints\nnetstat -an | grep -E \"4317|4318\"\n\n# Test gRPC endpoint\ngrpcurl -plaintext localhost:4317 list\n\n# Test HTTP endpoint\ncurl -v http://localhost:4318/v1/traces\n</code></pre>"},{"location":"operations/RUNBOOK/#issue-connector-not-running","title":"Issue: Connector Not Running","text":"<p>Symptoms: Connector state is FAILED or task state is FAILED</p> <p>Quick Fix: <pre><code># Check the error message\ncurl -s http://localhost:8083/connectors/&lt;name&gt;/status | jq '.tasks[0].trace'\n\n# Restart connector\ncurl -X POST http://localhost:8083/connectors/&lt;name&gt;/restart\n\n# If still failing, check config and redeploy\ncurl -X DELETE http://localhost:8083/connectors/&lt;name&gt;\ncurl -X POST http://localhost:8083/connectors -H \"Content-Type: application/json\" -d @connector.json\n</code></pre></p> <p>Common Causes: - Invalid configuration (bad port, invalid format) - Port already in use (4317 or 4318 bound to another process) - Missing dependencies (ClassNotFoundException) - Insufficient permissions to bind to ports</p>"},{"location":"operations/RUNBOOK/#monitoring","title":"Monitoring","text":""},{"location":"operations/RUNBOOK/#key-jmx-metrics","title":"Key JMX Metrics","text":"<p>The connector exposes JMX metrics under <code>io.conduktor.connect.otel:type=OpenTelemetryConnector,name=&lt;connector-name&gt;</code>:</p>"},{"location":"operations/RUNBOOK/#counter-metrics","title":"Counter Metrics","text":"<ul> <li>TracesReceived: Total traces received from OTLP</li> <li>Alert: Rate drops to 0 for &gt; 5 minutes \u2192 Connection issue or no traffic</li> <li> <p>Action: Check OTLP endpoint accessibility, verify applications are sending</p> </li> <li> <p>MetricsReceived: Total metrics received from OTLP</p> </li> <li>Alert: Rate drops to 0 for &gt; 5 minutes \u2192 Connection issue or no traffic</li> <li> <p>Action: Check OTLP endpoint accessibility, verify applications are sending</p> </li> <li> <p>LogsReceived: Total logs received from OTLP</p> </li> <li>Alert: Rate drops to 0 for &gt; 5 minutes \u2192 Connection issue or no traffic</li> <li> <p>Action: Check OTLP endpoint accessibility, verify applications are sending</p> </li> <li> <p>TracesDropped: Traces dropped due to queue full</p> </li> <li>Alert: Drop rate &gt; 1% \u2192 Queue capacity insufficient</li> <li> <p>Action: Increase <code>otlp.message.queue.size</code> or optimize Kafka throughput</p> </li> <li> <p>MetricsDropped: Metrics dropped due to queue full</p> </li> <li>Alert: Drop rate &gt; 1% \u2192 Queue capacity insufficient</li> <li> <p>Action: Increase <code>otlp.message.queue.size</code> or optimize Kafka throughput</p> </li> <li> <p>LogsDropped: Logs dropped due to queue full</p> </li> <li>Alert: Drop rate &gt; 1% \u2192 Queue capacity insufficient</li> <li> <p>Action: Increase <code>otlp.message.queue.size</code> or optimize Kafka throughput</p> </li> <li> <p>RecordsProduced: Total records written to Kafka</p> </li> <li>Alert: Lag (TotalMessagesReceived - RecordsProduced) &gt; 10000 \u2192 Processing backlog</li> <li>Action: Check Kafka broker health, review consumer lag</li> </ul>"},{"location":"operations/RUNBOOK/#queue-metrics","title":"Queue Metrics","text":"<ul> <li>TracesQueueSize: Current number of traces in queue</li> <li>MetricsQueueSize: Current number of metrics in queue</li> <li>LogsQueueSize: Current number of logs in queue</li> <li>QueueCapacity: Maximum queue capacity (per signal)</li> <li>MaxQueueUtilizationPercent: Highest utilization across all three queues</li> <li>Alert: Utilization &gt; 80% \u2192 Approaching capacity</li> <li>Action: Monitor for drops, consider increasing queue size</li> </ul>"},{"location":"operations/RUNBOOK/#derived-metrics","title":"Derived Metrics","text":"<ul> <li>TotalMessagesReceived: TracesReceived + MetricsReceived + LogsReceived</li> <li>TotalMessagesDropped: TracesDropped + MetricsDropped + LogsDropped</li> <li>TotalLagCount: TotalMessagesReceived - RecordsProduced</li> <li>Alert: &gt; 10000 \u2192 Processing backlog</li> <li> <p>Action: Review Kafka producer performance</p> </li> <li> <p>DropRate: (TotalMessagesDropped / TotalMessagesReceived) * 100</p> </li> <li>Alert: &gt; 1% \u2192 Significant message loss</li> <li>Action: Increase queue size or optimize throughput</li> </ul>"},{"location":"operations/RUNBOOK/#recommended-alerts","title":"Recommended Alerts","text":"<pre><code># Example Prometheus alerting rules\ngroups:\n  - name: otlp_connector\n    rules:\n      - alert: OTLPNoMessagesReceived\n        expr: rate(otlp_TotalMessagesReceived[5m]) == 0\n        for: 5m\n        annotations:\n          summary: \"OTLP connector not receiving messages\"\n          description: \"No messages received for 5 minutes on {{ $labels.connector_name }}\"\n\n      - alert: HighMessageDropRate\n        expr: otlp_DropRate &gt; 1\n        for: 5m\n        annotations:\n          summary: \"High message drop rate for {{ $labels.connector_name }}\"\n          description: \"Dropping {{ $value }}% of messages - queue capacity insufficient\"\n\n      - alert: HighProcessingLag\n        expr: otlp_TotalLagCount &gt; 10000\n        for: 5m\n        annotations:\n          summary: \"High processing lag for {{ $labels.connector_name }}\"\n          description: \"Lag count: {{ $value }} - Kafka throughput issue\"\n\n      - alert: HighQueueUtilization\n        expr: otlp_MaxQueueUtilizationPercent &gt; 80\n        for: 3m\n        annotations:\n          summary: \"High queue utilization for {{ $labels.connector_name }}\"\n          description: \"Queue at {{ $value }}% capacity - risk of drops\"\n\n      - alert: TracesQueueDropping\n        expr: increase(otlp_TracesDropped[5m]) &gt; 0\n        annotations:\n          summary: \"Traces being dropped on {{ $labels.connector_name }}\"\n          description: \"{{ $value }} traces dropped in last 5 minutes\"\n\n      - alert: MetricsQueueDropping\n        expr: increase(otlp_MetricsDropped[5m]) &gt; 0\n        annotations:\n          summary: \"Metrics being dropped on {{ $labels.connector_name }}\"\n          description: \"{{ $value }} metrics dropped in last 5 minutes\"\n\n      - alert: LogsQueueDropping\n        expr: increase(otlp_LogsDropped[5m]) &gt; 0\n        annotations:\n          summary: \"Logs being dropped on {{ $labels.connector_name }}\"\n          description: \"{{ $value }} logs dropped in last 5 minutes\"\n</code></pre>"},{"location":"operations/RUNBOOK/#common-issues","title":"Common Issues","text":""},{"location":"operations/RUNBOOK/#issue-1-otlp-receivers-not-listening","title":"Issue 1: OTLP Receivers Not Listening","text":"<p>Symptoms: - <code>netstat -an | grep 4317</code> shows nothing - <code>netstat -an | grep 4318</code> shows nothing - Applications cannot connect to OTLP endpoints - Logs showing \"Failed to start OTLP receiver\"</p> <p>Root Causes: 1. Ports already in use by another process 2. Insufficient permissions to bind to ports 3. Firewall blocking ports 4. Connector failed to start</p> <p>Resolution: <pre><code># Check what's using the ports\nlsof -i :4317\nlsof -i :4318\n\n# If ports are in use, either:\n# 1. Stop the conflicting process\n# 2. Use different ports in connector config:\n{\n  \"otlp.grpc.port\": \"14317\",\n  \"otlp.http.port\": \"14318\"\n}\n\n# Check firewall rules\nsudo ufw status\nsudo firewall-cmd --list-ports\n\n# Allow ports if needed\nsudo ufw allow 4317/tcp\nsudo ufw allow 4318/tcp\n\n# Restart connector\ncurl -X POST http://localhost:8083/connectors/otlp-source/restart\n</code></pre></p>"},{"location":"operations/RUNBOOK/#issue-2-no-messages-received","title":"Issue 2: No Messages Received","text":"<p>Symptoms: - <code>TotalMessagesReceived</code> metric not incrementing - OTLP endpoints are listening - No errors in logs</p> <p>Root Causes: 1. Applications not configured to send to connector 2. Applications using wrong endpoint 3. Network connectivity issues 4. Authentication/firewall blocking</p> <p>Resolution: <pre><code># Verify endpoints are accessible\ngrpcurl -plaintext localhost:4317 list\ncurl -v http://localhost:4318/v1/traces\n\n# Check application configuration\n# Should point to connector endpoints:\nexport OTEL_EXPORTER_OTLP_ENDPOINT=http://&lt;connector-host&gt;:4318\nexport OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf\n\n# Test sending data manually\n# Using otel-cli:\notel-cli exec --endpoint http://localhost:4318 \\\n  --service my-test-service -- echo \"test\"\n\n# Check connector logs for incoming requests\ntail -f $KAFKA_HOME/logs/connect.log | grep \"event=trace_received\\|event=metric_received\\|event=log_received\"\n\n# Actions:\n1. Verify application OTEL_EXPORTER_OTLP_ENDPOINT points to connector\n2. Check network connectivity from app to connector\n3. Verify firewall allows inbound on 4317, 4318\n4. Test with manual data send\n</code></pre></p>"},{"location":"operations/RUNBOOK/#issue-3-high-message-drop-rate","title":"Issue 3: High Message Drop Rate","text":"<p>Symptoms: - <code>DropRate</code> metric &gt; 1% - <code>TracesDropped</code>, <code>MetricsDropped</code>, or <code>LogsDropped</code> incrementing - <code>MaxQueueUtilizationPercent</code> at or near 100% - Logs showing \"Queue full, dropping message\" or \"event=trace_dropped\"</p> <p>Root Causes: 1. Queue capacity too small for traffic volume 2. Kafka broker throughput bottleneck 3. Inefficient message format (JSON vs Protobuf) 4. Consumer lag on target topics</p> <p>Resolution: <pre><code># Check queue metrics\njconsole # Connect to JMX and view queue metrics\n\n# Actions:\n1. Increase queue size:\n   \"otlp.message.queue.size\": \"50000\"  # default: 10000\n\n2. Switch to Protobuf format (smaller, faster):\n   \"otlp.message.format\": \"protobuf\"\n\n3. Check Kafka broker health:\n   kafka-broker-api-versions --bootstrap-server localhost:9092\n\n4. Monitor consumer lag on topics:\n   kafka-consumer-groups --bootstrap-server localhost:9092 \\\n     --group &lt;group&gt; --describe\n\n5. Optimize Kafka producer (in connect-distributed.properties):\n   producer.linger.ms=10\n   producer.batch.size=32768\n   producer.compression.type=lz4\n   producer.acks=1\n\n6. Scale Kafka brokers if needed\n</code></pre></p>"},{"location":"operations/RUNBOOK/#issue-4-processing-lag-building-up","title":"Issue 4: Processing Lag Building Up","text":"<p>Symptoms: - <code>TotalLagCount</code> increasing over time - Queue sizes growing - <code>RecordsProduced</code> not keeping pace with <code>TotalMessagesReceived</code></p> <p>Root Causes: 1. Kafka broker slowness or overload 2. Network issues to Kafka 3. Kafka topic partitions insufficient 4. Serialization bottleneck</p> <p>Resolution: <pre><code># Check Kafka broker metrics\nkafka-run-class kafka.tools.JmxTool \\\n  --object-name kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec \\\n  --jmx-url service:jmx:rmi:///jndi/rmi://localhost:9999/jmxrmi\n\n# Check topic configuration\nkafka-topics --bootstrap-server localhost:9092 \\\n  --describe --topic otlp-traces\n\n# Actions:\n1. Increase topic partitions for parallelism:\n   kafka-topics --alter --topic otlp-traces --partitions 12\n   kafka-topics --alter --topic otlp-metrics --partitions 12\n   kafka-topics --alter --topic otlp-logs --partitions 12\n\n2. Check Kafka broker disk I/O and network throughput:\n   iostat -xz 1\n   iftop\n\n3. Monitor Kafka Connect producer metrics:\n   curl http://localhost:8083/connectors/otlp-source/status\n\n4. Review connector logs for serialization errors:\n   grep \"ERROR\" $KAFKA_HOME/logs/connect.log\n\n5. Switch to Protobuf format if using JSON:\n   \"otlp.message.format\": \"protobuf\"\n</code></pre></p>"},{"location":"operations/RUNBOOK/#performance-tuning","title":"Performance Tuning","text":""},{"location":"operations/RUNBOOK/#queue-sizing","title":"Queue Sizing","text":"<p>Default: 10000 messages per signal type (30000 total)</p> <p>Recommendations: - Low-volume (&lt; 100 msg/s): 1000-5000 - Medium-volume (100-1000 msg/s): 10000-20000 (default) - High-volume (1000-5000 msg/s): 20000-50000 - Very high-volume (&gt; 5000 msg/s): 50000-100000</p> <p>Trade-offs: - Larger queue = more memory usage, better burst handling - Smaller queue = less memory, more drops under traffic spikes</p> <p>Memory formula: <pre><code>Memory \u2248 (queue_size \u00d7 avg_message_size \u00d7 3 queues)\n</code></pre></p> <p>Example: 50,000 queue \u00d7 2 KB avg \u00d7 3 = ~300 MB</p>"},{"location":"operations/RUNBOOK/#message-format-selection","title":"Message Format Selection","text":"<p>Production Recommendations:</p> Traffic Volume Recommended Format Reason Low (&lt; 100 msg/s) JSON Easier debugging Medium (100-1000 msg/s) JSON or Protobuf Either works High (&gt; 1000 msg/s) Protobuf 3-5x smaller, faster <p>JSON Benefits: - Human-readable for debugging - Easy downstream processing (ksqlDB, Kafka Streams) - No decoding required</p> <p>Protobuf Benefits: - 3-5x smaller message size - Faster serialization/deserialization - Lower bandwidth usage</p>"},{"location":"operations/RUNBOOK/#port-configuration","title":"Port Configuration","text":"<p>Default Ports: <pre><code>otlp.grpc.port=4317\notlp.http.port=4318\n</code></pre></p> <p>Custom Ports (avoid conflicts): <pre><code># Example for staging environment\notlp.grpc.port=5317\notlp.http.port=5318\n\n# Example for development\notlp.grpc.port=6317\notlp.http.port=6318\n</code></pre></p>"},{"location":"operations/RUNBOOK/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/RUNBOOK/#debug-logging","title":"Debug Logging","text":"<p>Enable debug logging for detailed troubleshooting:</p> <pre><code># Connector logging\nlog4j.logger.io.conduktor.connect.otel=DEBUG\n\n# gRPC logging\nlog4j.logger.io.grpc=DEBUG\n</code></pre>"},{"location":"operations/RUNBOOK/#common-log-messages","title":"Common Log Messages","text":"Log Message Severity Meaning Action \"event=task_starting\" INFO Task initialization Normal operation \"event=otlp_receiver_started\" INFO OTLP receivers started Normal operation \"event=trace_received\" DEBUG Trace received Normal operation \"event=trace_dropped\" WARN Trace dropped (queue full) Increase queue size \"event=task_metrics\" INFO Periodic metrics log Review metrics \"event=task_stopping\" INFO Graceful shutdown Normal shutdown \"Failed to start gRPC server\" ERROR gRPC startup failed Check port availability \"Failed to start HTTP server\" ERROR HTTP startup failed Check port availability"},{"location":"operations/RUNBOOK/#health-check","title":"Health Check","text":"<p>Create a health check script:</p> <pre><code>#!/bin/bash\n# health-check.sh\n\nCONNECTOR_NAME=\"otlp-source\"\nCONNECT_URL=\"http://localhost:8083\"\n\n# Check connector status\nSTATUS=$(curl -s $CONNECT_URL/connectors/$CONNECTOR_NAME/status | jq -r '.connector.state')\n\nif [ \"$STATUS\" != \"RUNNING\" ]; then\n  echo \"CRITICAL: Connector not running (state: $STATUS)\"\n  exit 2\nfi\n\n# Check task status\nTASK_STATUS=$(curl -s $CONNECT_URL/connectors/$CONNECTOR_NAME/status | jq -r '.tasks[0].state')\n\nif [ \"$TASK_STATUS\" != \"RUNNING\" ]; then\n  echo \"CRITICAL: Task not running (state: $TASK_STATUS)\"\n  exit 2\nfi\n\n# Check OTLP endpoints\nif ! netstat -an | grep -q 4317; then\n  echo \"WARNING: gRPC port 4317 not listening\"\n  exit 1\nfi\n\nif ! netstat -an | grep -q 4318; then\n  echo \"WARNING: HTTP port 4318 not listening\"\n  exit 1\nfi\n\necho \"OK: Connector healthy\"\nexit 0\n</code></pre>"},{"location":"operations/RUNBOOK/#otlp-endpoint-testing","title":"OTLP Endpoint Testing","text":"<p>Test gRPC endpoint: <pre><code># List available services\ngrpcurl -plaintext localhost:4317 list\n\n# Expected output:\n# opentelemetry.proto.collector.trace.v1.TraceService\n# opentelemetry.proto.collector.metrics.v1.MetricsService\n# opentelemetry.proto.collector.logs.v1.LogsService\n\n# Describe trace service\ngrpcurl -plaintext localhost:4317 describe opentelemetry.proto.collector.trace.v1.TraceService\n</code></pre></p> <p>Test HTTP endpoint: <pre><code># Test traces endpoint\ncurl -v http://localhost:4318/v1/traces \\\n  -H \"Content-Type: application/x-protobuf\"\n\n# Test metrics endpoint\ncurl -v http://localhost:4318/v1/metrics \\\n  -H \"Content-Type: application/x-protobuf\"\n\n# Test logs endpoint\ncurl -v http://localhost:4318/v1/logs \\\n  -H \"Content-Type: application/x-protobuf\"\n\n# Should return 200 or 400\n</code></pre></p>"},{"location":"operations/RUNBOOK/#recovery-procedures","title":"Recovery Procedures","text":""},{"location":"operations/RUNBOOK/#restart-connector","title":"Restart Connector","text":"<pre><code># Pause connector (stops receiving new messages)\ncurl -X PUT http://localhost:8083/connectors/otlp-source/pause\n\n# Wait for in-flight messages to flush\nsleep 10\n\n# Resume connector\ncurl -X PUT http://localhost:8083/connectors/otlp-source/resume\n\n# Verify status\ncurl -s http://localhost:8083/connectors/otlp-source/status | jq .\n</code></pre>"},{"location":"operations/RUNBOOK/#update-configuration","title":"Update Configuration","text":"<pre><code># Update connector configuration\ncat &gt; updated-config.json &lt;&lt;EOF\n{\n  \"connector.class\": \"io.conduktor.connect.otel.OpenTelemetrySourceConnector\",\n  \"tasks.max\": \"1\",\n  \"otlp.message.queue.size\": \"50000\",\n  \"otlp.message.format\": \"protobuf\"\n}\nEOF\n\ncurl -X PUT http://localhost:8083/connectors/otlp-source/config \\\n  -H \"Content-Type: application/json\" \\\n  -d @updated-config.json\n</code></pre>"},{"location":"operations/RUNBOOK/#emergency-shutdown","title":"Emergency Shutdown","text":"<p>If connector is misbehaving and needs immediate shutdown:</p> <pre><code># Option 1: Pause connector (graceful)\ncurl -X PUT http://localhost:8083/connectors/otlp-source/pause\n\n# Option 2: Delete connector (removes from cluster)\ncurl -X DELETE http://localhost:8083/connectors/otlp-source\n\n# Option 3: Restart Connect worker (nuclear option)\nkubectl delete pod -l app=kafka-connect\n# or\nsystemctl restart kafka-connect\n</code></pre>"},{"location":"operations/RUNBOOK/#capacity-planning","title":"Capacity Planning","text":""},{"location":"operations/RUNBOOK/#estimating-queue-size","title":"Estimating Queue Size","text":"<p>Formula: <pre><code>queue_size = (peak_throughput_per_second \u00d7 burst_duration_seconds) / 3\n</code></pre></p> <p>Divide by 3 because there are 3 queues (traces, metrics, logs).</p> <p>Example: - Peak: 5000 msg/s - Burst: 10 seconds - Queue size: (5000 \u00d7 10) / 3 = 16,667 per queue</p> <p>Recommendation: Add 50% buffer \u2192 25,000 per queue</p>"},{"location":"operations/RUNBOOK/#estimating-memory","title":"Estimating Memory","text":"<p>Formula: <pre><code>Memory = (queue_size \u00d7 avg_message_size \u00d7 3) + JVM_overhead\n</code></pre></p> <p>Example: - Queue: 25,000 - Avg message: 2 KB - Memory: (25,000 \u00d7 2 KB \u00d7 3) = 150 MB + overhead \u2248 200 MB</p> <p>Recommendation: Set heap to 4\u00d7 calculated = 800 MB minimum</p>"},{"location":"operations/RUNBOOK/#scaling-considerations","title":"Scaling Considerations","text":"<p>Single connector limitations: - One task per connector (cannot scale horizontally via tasks.max) - One pair of ports (gRPC + HTTP)</p> <p>To scale: 1. Run multiple connector instances on different ports 2. Use load balancer to distribute apps across connectors 3. Scale Kafka brokers to handle increased throughput</p>"},{"location":"operations/RUNBOOK/#contact-and-escalation","title":"Contact and Escalation","text":"<p>For issues not covered in this runbook:</p> <ol> <li>Review connector logs at DEBUG level</li> <li>Check Kafka Connect worker logs</li> <li>Verify Kafka broker health</li> <li>Check OTLP endpoint accessibility</li> <li>Consult project documentation: https://github.com/conduktor/kafka-connect-opentelemetry</li> <li>Open issue with:</li> <li>Connector configuration</li> <li>JMX metrics snapshot</li> <li>Relevant logs (last 1000 lines)</li> <li>Kafka Connect worker version</li> <li>Kafka broker version</li> <li>OpenTelemetry SDK version (if applicable)</li> </ol>"}]}